<!DOCTYPE html>
<html lang="en">
<head>
  <!--
    MIT License
    
    Copyright (c) 2025 NQR
    
    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the "Software"), to deal
    in the Software without restriction, including without limitation the rights
    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
    copies of the Software, and to permit persons to whom the Software is
    furnished to do so, subject to the following conditions:
    
    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.
    
    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
    SOFTWARE.
  -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ReSounder</title>
  <meta name="description" content="Rebuild audio from spectrograms to test hidden sound puzzles. Convert spectrogram images back into playable audio.">

  <!-- Open Graph -->
  <meta property="og:title" content="ReSounder | NQR Labs">
  <meta property="og:description" content="Rebuild audio from spectrograms to test hidden sound puzzles. Convert spectrogram images back into playable audio.">
  <meta property="og:image" content="https://nqrlabs.com/ReSounder/assets/images/logo.png">
  <meta property="og:url" content="https://nqrlabs.com/ReSounder/">
  <meta property="og:type" content="website">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="ReSounder | NQR Labs">
  <meta name="twitter:description" content="Rebuild audio from spectrograms to test hidden sound puzzles. Convert spectrogram images back into playable audio.">
  <meta name="twitter:image" content="https://nqrlabs.com/ReSounder/assets/images/logo.png">

  <!-- Canonical URL -->
  <link rel="canonical" href="https://nqrlabs.com/ReSounder/">

  <!-- Favicon links -->
  <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicon-16x16.png">
  <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicon-32x32.png">
  <link rel="apple-touch-icon" sizes="180x180" href="assets/images/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="assets/images/android-chrome-192x192.png">
  <link rel="icon" type="image/png" sizes="512x512" href="assets/images/android-chrome-512x512.png">
  <style>
    /* ============================================
       INVERTER CSS VARIABLES
       ============================================ */
    :root {
      --bg: #0c1020;
      --card: #151c3b;
      --ink: #eef1ff;
      --dim: #b9c6ef;
      --border: #2b3868;
      --accent: #1fc9aa;
      --accent-hover: #18b79a;
      --accent-dark: #17b399;
      --input-bg: #0f1432;
    }

    /* ============================================
       BASE STYLES
       ============================================ */
    body {
      margin: 0;
      padding: 0;
      background: var(--bg);
      color: var(--ink);
      font-family: system-ui, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: center;
      -webkit-font-smoothing: antialiased;
      -moz-osx-font-smoothing: grayscale;
    }

    h2 {
      margin: 16px 0 8px;
      font-weight: 600;
      letter-spacing: 0.3px;
    }

    /* ============================================
       CANVAS CONTAINER & CANVAS
       ============================================ */
    .canvas-container {
      max-width: 95vw;
      max-height: 60vh;
      overflow: auto;
      margin: 10px 0;
      border: 1px solid var(--border);
      border-radius: 8px;
      background: #000;
      display: flex;
      align-items: flex-end; /* Bottom-align to show low frequencies first */
      position: relative;
      scroll-behavior: smooth;
      -webkit-overflow-scrolling: touch; /* Smooth scrolling on iOS */
    }

    canvas {
      display: block;
      background: #000;
      /* Scaling will be applied via inline style based on aspect ratio */
      image-rendering: pixelated;
      image-rendering: -moz-crisp-edges;
      image-rendering: crisp-edges;
      cursor: pointer; /* Indicate clickability for seeking */
    }

    /* Thumbnail preview near file input */
    .thumbnail-preview {
      max-width: 300px;
      max-height: 150px;
      margin: 10px auto; /* Center horizontally */
      border: 1px solid var(--border);
      border-radius: 4px;
      background: #000;
      display: none; /* Hidden until image loads */
    }

    /* Playhead overlay */
    .playhead {
      position: absolute;
      left: 0;
      bottom: 0;
      top: 0;
      width: 2px;
      background: rgba(255, 50, 50, 0.9);
      box-shadow: 0 0 8px rgba(255, 50, 50, 0.8), 0 0 2px rgba(255, 255, 255, 0.6);
      pointer-events: none; /* Allow clicks to pass through to canvas */
      z-index: 10;
      display: none; /* Hidden until audio loads */
      transition: left 0.05s linear; /* Smooth movement during playback */
    }

    .playhead.dragging {
      transition: none; /* No transition during drag for immediate response */
      box-shadow: 0 0 12px rgba(255, 50, 50, 1), 0 0 4px rgba(255, 255, 255, 0.8);
    }

    /* Time tooltip shown during drag */
    .playhead-tooltip {
      position: absolute;
      background: rgba(0, 0, 0, 0.9);
      color: #fff;
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 12px;
      font-family: monospace;
      pointer-events: none;
      z-index: 11;
      display: none;
      white-space: nowrap;
      transform: translate(-50%, -100%);
      margin-top: -8px;
    }

    /* ============================================
       CONTROLS SECTION
       ============================================ */
    .controls {
      display: flex;
      flex-direction: column;
      align-items: center;
      width: 92vw;
      max-width: 760px;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 14px;
      padding: 20px;
      margin: 10px 0;
      box-shadow: 0 10px 30px rgba(0,0,0,.35);
      overflow: visible;
    }

    .control-section {
      width: 100%;
      padding: 16px 0;
      border-bottom: 1px solid var(--border);
    }

    .control-section h3 {
      margin: 0 0 12px 0;
      font-size: 15px;
      font-weight: 600;
      color: var(--accent);
      text-transform: uppercase;
      letter-spacing: 0.5px;
      text-align: left;
    }

    .control-section:last-of-type {
      border-bottom: none;
    }

    .row {
      display: flex;
      flex-wrap: wrap;
      gap: 10px 16px;
      justify-content: center;
      align-items: end;
      width: 100%;
      margin: 6px 0;
      overflow: visible;
    }

    /* ============================================
       FORM ELEMENTS
       ============================================ */
    label {
      font-size: 14px;
      font-weight: 500;
      display: flex;
      flex-direction: column;
      gap: 4px;
      color: var(--dim);
      overflow: visible;
      position: relative;
    }

    input[type="number"],
    select {
      background: var(--input-bg);
      border: 1px solid var(--border);
      color: var(--ink);
      border-radius: 6px;
      padding: 6px 8px;
      font-size: 14px;
      transition: border-color 0.2s ease, box-shadow 0.2s ease;
    }

    input[type="number"]:focus,
    select:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 3px rgba(31, 201, 170, 0.1);
    }

    input[type="file"] {
      background: var(--input-bg);
      border: 1px solid var(--border);
      color: var(--ink);
      border-radius: 6px;
      padding: 6px 8px;
      font-size: 14px;
      min-width: 100px;
      transition: border-color 0.2s ease, box-shadow 0.2s ease;
    }

    input[type="file"]:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 3px rgba(31, 201, 170, 0.1);
    }

    input[type="file"] {
      cursor: pointer;
      padding: 8px 12px;
      width: auto;
      min-width: 300px;
    }

    /* Modern browsers (Chrome, Edge, Firefox, Safari 14+) */
    input[type="file"]::file-selector-button {
      background: var(--accent);
      color: #0b0f14;
      border: 1px solid var(--accent-dark);
      border-radius: 8px;
      padding: 10px 16px;
      cursor: pointer;
      font-weight: 600;
      font-size: 14px;
      letter-spacing: 0.3px;
      transition: all 0.15s ease;
      box-shadow: 0 2px 4px rgba(31, 201, 170, 0.2);
      margin-right: 10px; /* space before filename text */
    }
    
    /* Hover/active to match your button styles */
    input[type="file"]::file-selector-button:hover {
      background: var(--accent-hover);
      border-color: var(--accent-hover);
      transform: translateY(-1px);
      box-shadow: 0 4px 8px rgba(31, 201, 170, 0.3);
    }
    input[type="file"]::file-selector-button:active {
      transform: translateY(0);
      box-shadow: 0 1px 2px rgba(31, 201, 170, 0.2);
    }
    
    /* Safari <14 (legacy WebKit fallback) */
    input[type="file"]::-webkit-file-upload-button {
      background: var(--accent);
      color: #0b0f14;
      border: 1px solid var(--accent-dark);
      border-radius: 8px;
      padding: 10px 16px;
      cursor: pointer;
      font-weight: 600;
      font-size: 14px;
      letter-spacing: 0.3px;
      transition: all 0.15s ease;
      box-shadow: 0 2px 4px rgba(31, 201, 170, 0.2);
      margin-right: 10px;
    }
    input[type="file"]::-webkit-file-upload-button:hover {
      background: var(--accent-hover);
      border-color: var(--accent-hover);
      transform: translateY(-1px);
      box-shadow: 0 4px 8px rgba(31, 201, 170, 0.3);
    }
    input[type="file"]::-webkit-file-upload-button:active {
      transform: translateY(0);
      box-shadow: 0 1px 2px rgba(31, 201, 170, 0.2);
    }


    input[type="range"] {
      width: 120px;
      accent-color: var(--accent);
    }

    input[type="checkbox"] {
      width: 18px;
      height: 18px;
      accent-color: var(--accent);
      cursor: pointer;
    }

    /* Colormap Radio Button List */
    .colormap-list {
      display: flex;
      flex-direction: column;
      gap: 4px;
      background: var(--input-bg);
      border: 1px solid var(--border);
      border-radius: 6px;
      padding: 8px;
      width: 200px;
    }

    .colormap-option {
      display: flex;
      flex-direction: row;
      align-items: center;
      gap: 8px;
      padding: 4px 6px;
      border-radius: 4px;
      cursor: pointer;
      transition: background 0.15s ease;
    }

    .colormap-option:hover {
      background: rgba(31, 201, 170, 0.1);
    }

    .colormap-option input[type="radio"] {
      cursor: pointer;
      accent-color: var(--accent);
      flex-shrink: 0;
      margin: 0;
    }

    .colormap-option input[type="radio"]:checked + .colormap-name {
      color: var(--accent);
      font-weight: 600;
    }

    .colormap-name {
      font-size: 13px;
      color: var(--ink);
      width: 65px;
      flex-shrink: 0;
    }

    .option-gradient {
      height: 8px;
      border-radius: 2px;
      width: 90px;
      flex-shrink: 0;
      border: 0px solid transparent;
    }

    .gradient-grayscale {
      background: linear-gradient(to right, #ffffff, #000000) !important;
    }

    .gradient-viridis {
      background: linear-gradient(to right, #440154, #3b528b, #21918c, #5ec962, #fde725) !important;
    }
    
    .gradient-plasma {
      background: linear-gradient(to right, #0d0887, #7e03a8, #cc4778, #f89540, #f0f921) !important;
    }
    
    .gradient-inferno {
      background: linear-gradient(to right, #000004, #420a68, #932667, #dd513a, #fca50a, #fcffa4) !important;
    }
    
    .gradient-magma {
      background: linear-gradient(to right, #000004, #3b0f70, #8c2981, #de4968, #fe9f6d, #fcfdbf) !important;
    }
    
    .gradient-jet {
      background: linear-gradient(to right, #00007f, #0000ff, #00ffff, #00ff00, #ffff00, #ff0000, #7f0000) !important;
    }
    
    .gradient-hot {
      background: linear-gradient(to right, #000000, #ff0000, #ffff00, #ffffff) !important;
    }
    
    .gradient-cool {
      background: linear-gradient(to right, #00ffff, #ff00ff) !important;
    }
    
    .gradient-parula {
      background: linear-gradient(to right, #352a87, #0f5cdd, #00a6ff, #ffed00, #ff4d00) !important;
    }

    .gradient-roseus {
      background: linear-gradient(to right, #010101, #06234f, #7e17a2, #d93a6f, #f6ba6b, #fffbf9) !important;
    }

    /* ============================================
       COLORMAP DROPDOWN WITH VISUAL PREVIEWS
       ============================================ */
    #colormapSelect {
      background: var(--input-bg);
      border: 1px solid var(--border);
      color: var(--ink);
      border-radius: 6px;
      padding: 6px 8px;
      font-size: 14px;
      cursor: pointer;
      min-width: 180px;
    }

    #colormapSelect option {
      background: var(--input-bg);
      color: var(--ink);
      padding: 8px;
      font-size: 14px;
    }

    /* ============================================
       BUTTONS - TEAL/CYAN ACCENT
       ============================================ */
    button {
      background: var(--accent);
      color: #0b0f14;
      border: 1px solid var(--accent-dark);
      border-radius: 8px;
      padding: 10px 16px;
      cursor: pointer;
      font-weight: 600;
      font-size: 14px;
      letter-spacing: 0.3px;
      transition: all 0.15s ease;
      box-shadow: 0 2px 4px rgba(31, 201, 170, 0.2);
    }

    button:hover {
      background: var(--accent-hover);
      border-color: var(--accent-hover);
      transform: translateY(-1px);
      box-shadow: 0 4px 8px rgba(31, 201, 170, 0.3);
    }

    button:active {
      transform: translateY(0);
      box-shadow: 0 1px 2px rgba(31, 201, 170, 0.2);
    }

    button:disabled {
      background: #1a2047;
      border-color: var(--border);
      color: var(--dim);
      opacity: 0.6;
      cursor: not-allowed;
      transform: none;
      box-shadow: none;
    }

    /* Camera button - compact style next to file input */
    .camera-btn {
      padding: 6px 10px;
      font-size: 16px;
      min-width: auto;
      vertical-align: middle;
      margin-left: 8px;
    }

    /* Camera modal overlay */
    .camera-overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0, 0, 0, 0.9);
      z-index: 10000;
      display: none;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }

    .camera-overlay.active {
      display: flex;
    }

    .camera-container {
      position: relative;
      max-width: 90vw;
      max-height: 70vh;
    }

    #cameraVideo {
      max-width: 90vw;
      max-height: 70vh;
      border-radius: 8px;
      background: #000;
    }

    .camera-controls {
      display: flex;
      gap: 16px;
      margin-top: 20px;
      align-items: center;
    }

    .camera-controls button {
      min-width: 120px;
    }

    #flashBtn {
      min-width: auto;
      width: 50px;
      height: 50px;
      font-size: 20px;
      border-radius: 50%;
      padding: 0;
      transition: background 0.2s, box-shadow 0.2s;
    }

    #flashBtn.active {
      background: var(--accent);
      box-shadow: 0 0 12px var(--accent);
    }

    #captureBtn {
      font-size: 24px;
      padding: 16px 32px;
      border-radius: 50%;
      min-width: auto;
      width: 70px;
      height: 70px;
    }

    .camera-close {
      position: absolute;
      top: 20px;
      right: 20px;
      background: rgba(0, 0, 0, 0.6);
      color: var(--text);
      border: 1px solid var(--border);
      font-size: 24px;
      width: 44px;
      height: 44px;
      border-radius: 50%;
      cursor: pointer;
      z-index: 10001;
    }

    .camera-close:hover {
      background: rgba(31, 201, 170, 0.3);
    }

    .camera-status {
      color: var(--dim);
      font-size: 14px;
      margin-top: 12px;
      text-align: center;
    }

    .camera-status.error {
      color: #ff6b6b;
    }

    /* Image Adjustments Panel */
    .adjust-panel {
      display: none;
      margin: 12px auto;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 8px;
      overflow: hidden;
      max-width: 400px;
    }

    .adjust-panel.visible {
      display: block;
    }

    .adjust-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 10px 14px;
      cursor: pointer;
      background: rgba(31, 201, 170, 0.05);
      border-bottom: 1px solid var(--border);
      user-select: none;
    }

    .adjust-header:hover {
      background: rgba(31, 201, 170, 0.1);
    }

    .adjust-toggle {
      color: var(--dim);
      transition: transform 0.2s;
    }

    .adjust-panel.collapsed .adjust-toggle {
      transform: rotate(-90deg);
    }

    .adjust-panel.collapsed .adjust-content {
      display: none;
    }

    .adjust-content {
      padding: 14px;
    }

    .adjust-row {
      display: flex;
      align-items: center;
      gap: 12px;
      margin-bottom: 12px;
    }

    .adjust-row label {
      width: 90px;
      font-size: 13px;
      color: var(--dim);
    }

    .adjust-row input[type="range"] {
      flex: 1;
      height: 6px;
      background: var(--border);
      border-radius: 3px;
      cursor: pointer;
      -webkit-appearance: none;
      appearance: none;
    }

    .adjust-row input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      width: 16px;
      height: 16px;
      background: var(--accent);
      border-radius: 50%;
      cursor: pointer;
      box-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .adjust-row input[type="range"]::-moz-range-thumb {
      width: 16px;
      height: 16px;
      background: var(--accent);
      border-radius: 50%;
      cursor: pointer;
      border: none;
      box-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .adjust-value {
      width: 36px;
      text-align: right;
      font-size: 12px;
      color: var(--text);
      font-family: monospace;
    }

    .rotate-buttons {
      display: flex;
      gap: 4px;
      flex: 1;
    }

    .rotate-btn {
      flex: 1;
      padding: 4px 8px;
      font-size: 11px;
      background: var(--surface);
      border: 1px solid var(--border);
      color: var(--text);
      border-radius: 4px;
      cursor: pointer;
      transition: background 0.2s, border-color 0.2s;
    }

    .rotate-btn:hover {
      background: rgba(31, 201, 170, 0.2);
    }

    .rotate-btn.active {
      background: var(--accent);
      color: #000;
      border-color: var(--accent);
    }

    .adjust-section-label {
      font-size: 11px;
      color: var(--dim);
      text-transform: uppercase;
      letter-spacing: 0.5px;
      margin: 14px 0 8px;
      padding-top: 10px;
      border-top: 1px solid var(--border);
    }

    .adjust-buttons {
      display: flex;
      gap: 10px;
      margin-top: 14px;
    }

    .adjust-buttons button {
      flex: 1;
      padding: 8px 12px;
      font-size: 13px;
      min-width: auto;
    }

    /* Special styling for primary action buttons */
    #invertBtn,
    #downloadBtn {
      font-size: 15px;
      padding: 12px 20px;
      min-width: 140px;
    }

    /* ============================================
       AUDIO PLAYER
       ============================================ */
    audio {
      width: 100%;
      max-width: 760px;
      margin: 6px 0 12px;
      border-radius: 8px;
    }

    /* ============================================
       DEBUG LOG
       ============================================ */
    .debug {
      background: var(--card);
      padding: 12px;
      margin-top: 10px;
      width: 92vw;
      max-width: 760px;
      max-height: 300px;
      overflow: auto;
      font-size: 12px;
      font-family: 'Courier New', monospace;
      border: 1px solid var(--border);
      border-radius: 8px;
      text-align: left;
      white-space: pre-wrap;
      box-shadow: 0 4px 12px rgba(0,0,0,.25);
    }

    /* ============================================
       HIGHLIGHTED INPUTS
       ============================================ */
    .highlight-input {
      background: rgba(31, 201, 170, 0.08) !important;
      border-color: var(--accent) !important;
    }

    /* ============================================
       TIPS AND TROUBLESHOOTING
       ============================================ */
    .tip-footer {
      margin-top: 0px;
      margin-bottom: 0px;
      padding: 0px;
      font-size: 11px;
      color: var(--dim);
      opacity: 0.7;
      cursor: pointer;
      transition: opacity 0.2s ease;
    }

    .tip-footer:hover {
      opacity: 1;
    }

    .tip-modal {
      display: none;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: var(--card);
      border: 2px solid var(--border);
      border-radius: 12px;
      padding: 20px;
      max-width: 500px;
      width: 90%;
      max-height: 80vh;
      overflow-y: auto;
      box-shadow: 0 20px 60px rgba(0,0,0,.6);
      z-index: 1000;
    }

    .tip-modal.show {
      display: block;
    }

    .tip-modal h3 {
      text-align: center;
      margin-top: 0;
      color: var(--ink);
    }

    .tip-modal pre {
      text-align: left;
      white-space: pre-wrap;
      font-size: 11px;
      line-height: 1.5;
      color: var(--dim);
    }

    .tip-modal pre b{
      font-size: 14px;
    }

    .tip-modal-close {
      float: right;
      cursor: pointer;
      font-size: 24px;
      color: var(--dim);
      transition: color 0.2s ease;
    }

    .tip-modal-close:hover {
      color: var(--ink);
    }

    .tip-overlay {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.7);
      z-index: 999;
    }

    .tip-overlay.show {
      display: block;
    }

    /* ============================================
       LICENSE FOOTER
       ============================================ */
    .license-footer {
      width: 100%;
      max-width: 760px;
      border-top: 2px solid #3b528b;
      margin-top: auto;
      margin-bottom: 0px;
      padding: 10px 0px;
      font-size: 0.68rem;
      color: #a9a9b2;
      opacity: 0.7;
      transition: opacity 0.3s ease;
      text-align: center;
      text-decoration: none;
    }
    
    .license-footer a {
      color: #a9a9b2;
      text-decoration: none;
      cursor: pointer;
    }
    
    .license-footer a:hover { 
      color: #97f3d2;
      cursor: pointer;
      opacity: 1;
      text-decoration: underline;
    }


    .license-modal {
      display: none;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: var(--card);
      border: 2px solid var(--border);
      border-radius: 12px;
      padding: 20px;
      padding-bottom: 0px;
      max-width: 500px;
      width: 90%;
      max-height: 80vh;
      overflow-y: auto;
      box-shadow: 0 20px 60px rgba(0,0,0,.6);
      z-index: 1000;
      text-align: left;
    }

    .license-modal.show {
      display: block;
    }

    .license-modal h3 {
      margin-top: 0;
      color: var(--ink);
    }

    .license-modal pre {
      white-space: pre-wrap;
      font-size: 11px;
      line-height: 1.5;
      color: var(--dim);
    }

    .license-modal-close {
      float: right;
      cursor: pointer;
      font-size: 24px;
      color: var(--dim);
      transition: color 0.2s ease;
    }

    .license-modal-close:hover {
      color: var(--ink);
    }

    .license-overlay {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.7);
      backdrop-filter: blur(4px);
      z-index: 999;
    }

    .license-overlay.show {
      display: block;
    }

    /* ============================================
       RESPONSIVE DESIGN
       ============================================ */
    @media (max-width: 640px) {
      .controls {
        padding: 16px 12px;
        width: 95vw;
      }

      .row {
        gap: 8px 12px;
      }

      label {
        font-size: 13px;
      }

      input[type="number"],
      select {
        font-size: 13px;
        padding: 5px 7px;
      }

      input[type="file"] {
        margin: 8px;
        padding: 8px 12px;
        background: var(--input-bg);
        border: 1px solid var(--border);
        border-radius: 8px;
        color: var(--ink);
        cursor: pointer;
        min-width: 200px;
        font-size: 14px;
      }

      button {
        padding: 8px 14px;
        font-size: 13px;
      }

      #invertBtn,
      #downloadBtn {
        font-size: 14px;
        padding: 10px 16px;
        min-width: 120px;
      }
    }
  </style>
  <!-- ONNX Runtime Web for Neural Vocoder (MIT License) -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.17.1/dist/ort.min.js"></script>
</head>
<body>
  <img src="assets/images/logo.png" alt="ReSounder Logo" style="max-width: 200px; height: auto; margin: 20px 0 10px;">
  <h2>ReSounder</h2>
  <p style="color: var(--dim); font-size: 14px; margin: -5px 0 15px; font-style: italic;">A lightweight spectrogram inverter by NQR</p>
  
  <div class="controls">
    <!-- Hidden controls that maintain values -->
    <div style="display:none;">
      <label>marginLeft <input type="number" id="marginLeft" value="0" step="1"></label>
      <label id="cropHeightLabel">cropHeight <input type="number" id="cropHeight" value="193" step="1"></label>
      <label><input type="checkbox" id="applyFloor" checked>Apply low-level floor</label>
    </div>

    <!-- SECTION: Spectrogram Input -->
    <div class="control-section">
      <div style="display: flex; align-items: center; gap: 16px; margin-bottom: 8px;">
        <h3 style="margin: 0;">üñºÔ∏è SPECTROGRAM INPUT</h3>
        <div class="tip-footer" id="tipLink" style="margin: 0;">
          Tips for getting good results
        </div>
      </div>

      <div style="margin: 10px 0;">
        <input type="file" id="imageInput" accept="image/png,image/jpeg,image/jpg,image/webp,image/*">
        <button type="button" id="cameraBtn" class="camera-btn" title="Capture from camera">üì∑</button>
        <span style="color: var(--dim); font-size: 13px; font-style: italic;">or Ctrl+V to paste</span>
      </div>
      <!-- Thumbnail preview for quick reference -->
      <canvas id="thumbnail" class="thumbnail-preview"></canvas>

      <!-- Image Adjustments Panel -->
      <div class="adjust-panel" id="adjustPanel">
        <div class="adjust-header" id="adjustHeader">
          <span>Image Adjustments</span>
          <span class="adjust-toggle">‚ñº</span>
        </div>
        <div class="adjust-content" id="adjustContent">
          <div class="adjust-row">
            <label>Brightness</label>
            <input type="range" id="adjustBrightness" min="-100" max="100" value="0">
            <span class="adjust-value" id="adjustBrightnessVal">0</span>
          </div>
          <div class="adjust-row">
            <label>Contrast</label>
            <input type="range" id="adjustContrast" min="-100" max="100" value="0">
            <span class="adjust-value" id="adjustContrastVal">0</span>
          </div>
          <div class="adjust-row">
            <label>Temperature</label>
            <input type="range" id="adjustTemperature" min="-100" max="100" value="0">
            <span class="adjust-value" id="adjustTemperatureVal">0</span>
          </div>
          <div class="adjust-row">
            <label>Lens</label>
            <input type="range" id="adjustLens" min="-50" max="50" value="0" step="1">
            <span class="adjust-value" id="adjustLensVal">0</span>
          </div>
          <div class="adjust-row">
            <label>Rotate</label>
            <div class="rotate-buttons">
              <button type="button" id="rotate0" class="rotate-btn active" title="0¬∞">0¬∞</button>
              <button type="button" id="rotate90" class="rotate-btn" title="90¬∞">90¬∞</button>
              <button type="button" id="rotate180" class="rotate-btn" title="180¬∞">180¬∞</button>
              <button type="button" id="rotate270" class="rotate-btn" title="270¬∞">270¬∞</button>
            </div>
          </div>
          <div class="adjust-row">
            <label>Fine Rotate</label>
            <input type="range" id="adjustRotation" min="-30" max="30" value="0" step="0.1">
            <span class="adjust-value" id="adjustRotationVal">0¬∞</span>
          </div>
          <div class="adjust-row">
            <label>Keystone V</label>
            <input type="range" id="keystoneV" min="-50" max="50" value="0" step="1">
            <span class="adjust-value" id="keystoneVVal">0</span>
          </div>
          <div class="adjust-row">
            <label>Keystone H</label>
            <input type="range" id="keystoneH" min="-50" max="50" value="0" step="1">
            <span class="adjust-value" id="keystoneHVal">0</span>
          </div>
          <div class="adjust-section-label">Crop</div>
          <div class="adjust-row">
            <label>Left</label>
            <input type="range" id="cropLeft" min="0" max="50" value="0" step="0.5">
            <span class="adjust-value" id="cropLeftVal">0%</span>
          </div>
          <div class="adjust-row">
            <label>Right</label>
            <input type="range" id="cropRight" min="0" max="50" value="0" step="0.5">
            <span class="adjust-value" id="cropRightVal">0%</span>
          </div>
          <div class="adjust-row">
            <label>Top</label>
            <input type="range" id="cropTop" min="0" max="50" value="0" step="0.5">
            <span class="adjust-value" id="cropTopVal">0%</span>
          </div>
          <div class="adjust-row">
            <label>Bottom</label>
            <input type="range" id="cropBottom" min="0" max="50" value="0" step="0.5">
            <span class="adjust-value" id="cropBottomVal">0%</span>
          </div>
          <div class="adjust-buttons">
            <button type="button" id="adjustGrayscaleBtn">Grayscale</button>
            <button type="button" id="adjustVistaBtn">Vista</button>
          </div>
          <div class="adjust-buttons">
            <button type="button" id="adjustAutoBtn">Auto Levels</button>
            <button type="button" id="adjustResetBtn">Reset</button>
          </div>
          <div class="adjust-buttons" style="margin-top: 16px; border-top: 1px solid var(--border); padding-top: 14px;">
            <button type="button" id="adjustSaveBtn">Save Adjusted Image</button>
          </div>
        </div>
      </div>

      <!-- Tip Modal -->
      <div class="tip-overlay" id="tipOverlay"></div>
      <div class="tip-modal" id="tipModal">
        <span class="tip-modal-close" id="tipClose">&times;</span>
        <h3>Tips & Troubleshooting</h3>
        <pre>
<ol>
Best tip for future troubleshooting: experiment until you gain an intuition about common issues.

<li><b>Speech sounds distorted or "robotic"</b>
Symptom: Vowels are smeared, consonants feel metallic or synthetic.
Likely cause: Frequency axis scale does not match original spectrogram.
Fix: Try switching Frequency Scale (e.g., Linear ? Log).  Ensure Min/Max Frequency align with the original signal's content.</li>

<li><b>Audio is the wrong pitch (too high or too low)</b>
Symptom: Everything sounds like chipmunks or deep giants.
Likely cause: Frequency bounds do not match the image's real spectral range. The height of the spectrogram determines the musical pitch mapping.
Fix: Increase Max Frequency if the audio sounds too deep. Decrease Min Frequency if the audio sounds too high.</li>

<li><b>Audio timing seems stretched or compressed</b>
Symptom: Speech rate or tempo sounds wrong.
Likely cause: Horizontal scale mismatch. Time axis scaling changes the actual duration mapping.
Fix: Adjust Duration (sec) to match original export.  Re-render preview with new value before reconstruction.</li>

<li><b>Audio is just loud impulsive noise</b>
Symptom: Energy bursts appear instead of smooth tonal content.
Likely cause: FFT size too small for the image's time resolution. If the time window is too short, harmonic structure collapses into broadband transients.
Fix: Increase FFT Size to improve frequency resolution. Reduce Duration (sec) if needed to balance performance. Ideal FFT sizes for speech sampled at 44.1-48 kHz are around 2048 and 4096.</li>

<li><b>Audio sounds "sing-songy"</b>
Symptom: Sustained tones rise and fall unnaturally, creating a melodic lilt that was not present in the original audio.
Likely cause: The FFT size is too large, causing excessive smoothing over time and smearing rapid changes in pitch and articulation.
Fix: Reduce FFT Size to improve time resolution, preserving more natural speech and transient detail. Ideal FFT sizes for speech sampled at 44.1-48 kHz are around 2048 and 4096.</li>

<li><b>Audio feels muffled or missing detail</b>
Symptom: High-frequency or Low-frequency content is dull or absent, or not enough detail in spectrogram.
Likely cause: The spectrogram's maximum frequency set too low, or minimum frequency set too high, or spectrogram height too small, or FFT size is too small, or Noise Floor (dB) is too small. Nonlinear scales compress/stretch near the top/bottom of spectrograms.
Fix if you didn't create the spectrogram: Check if the frequency scale was exported as log but decoded linear. Increase Noise Floor (dB).
Fix if you created the spectrogram: Raise the maximum frequency, or lower the minimum frequency, or increase FFT size, or increase image height. Use Linear scale instead of Log, Mel or Bark to maximize detail in the spectrogram.</li>

<li><b>Audio sounds like white noise</b>
Symptom: Audio sounds like white/broadband noise though the waveform appears correct.
Likely cause: The colormap is being interpreted in the wrong orientation.
Fix: Toggle Invert Colors to correct the intensity mapping.</li>

<li><b>Audio is too quiet or fades into silence</b>
Symptom: Everything is faint though the waveform appears correct.
Likely cause: Too wide a Dynamic Range or incorrect intensity normalization. Very low pixel values correspond to extreme attenuation in dB space.
Fix: Reduce Dynamic Range (dB). Increase Noise Floor (dB). Ensure color inversion (if applied) matches original export. Increase Pre-gain or Post-gain.</li>

<li><b>Audio has a high-pitched hissing floor</b>
Symptom: Constant noise underlying all playback.
Likely cause: Noise pixels mapped to non-zero magnitude during dB-to-linear conversion. Small values near the noise floor get amplified in reconstruction.
Fix: Decrease Noise Floor (dB).  Increase Dynamic Range (dB) slightly.</li>

<li><b>Audio has "underwater" / "phasing" artifacts</b>
Symptom: Warbly, chorus-like sound.
Likely cause: Phase propagation struggling due to abrupt changes.
Fix: Ensure FFT Size & Duration (sec) is close to original. Unfortunately, this is the main symptom of phase reconstruction and can't be entirely removed.</li>
</ol>
        </pre>
      </div>

      <!-- Camera Capture Modal -->
      <div class="camera-overlay" id="cameraOverlay">
        <button class="camera-close" id="cameraClose" title="Close camera">&times;</button>
        <div class="camera-container">
          <video id="cameraVideo" autoplay playsinline></video>
        </div>
        <div class="camera-controls">
          <button type="button" id="flashBtn" title="Toggle flash" style="display:none;">üî¶</button>
          <button type="button" id="switchCameraBtn" title="Switch camera">üîÑ</button>
          <button type="button" id="captureBtn" title="Capture frame">üì∑</button>
        </div>
        <div class="camera-status" id="cameraStatus">Initializing camera...</div>
      </div>

      <div class="row">
        <div style="display: flex; align-items: flex-start; gap: 16px;">
          <div>
            <label style="display: block; margin-bottom: 8px; color: var(--dim);">Colormap</label>
            <div class="colormap-list">
              <label class="colormap-option">
                <input type="radio" name="colormap" value="grayscale" checked>
                <span class="colormap-name">Grayscale</span>
                <div class="option-gradient gradient-grayscale"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="viridis">
                <span class="colormap-name">Viridis</span>
                <div class="option-gradient gradient-viridis"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="plasma">
                <span class="colormap-name">Plasma</span>
                <div class="option-gradient gradient-plasma"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="inferno">
                <span class="colormap-name">Inferno</span>
                <div class="option-gradient gradient-inferno"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="magma">
                <span class="colormap-name">Magma</span>
                <div class="option-gradient gradient-magma"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="jet">
                <span class="colormap-name">Jet</span>
                <div class="option-gradient gradient-jet"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="hot">
                <span class="colormap-name">Hot</span>
                <div class="option-gradient gradient-hot"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="cool">
                <span class="colormap-name">Cool</span>
                <div class="option-gradient gradient-cool"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="parula">
                <span class="colormap-name">Parula</span>
                <div class="option-gradient gradient-parula"></div>
              </label>

              <label class="colormap-option">
                <input type="radio" name="colormap" value="roseus">
                <span class="colormap-name">Roseus</span>
                <div class="option-gradient gradient-roseus"></div>
              </label>
            </div>

            <label style="display: flex; flex-direction: row; align-items: center; gap: 8px; margin-top: 8px; width: fit-content; margin-left: auto; margin-right: auto; cursor: pointer;">
              <input type="checkbox" id="invertColorsIn" style="margin: 0;">
              <span>Invert Colors</span>
            </label>
            <label style="display: flex; flex-direction: row; align-items: center; gap: 8px; margin-top: 4px; width: fit-content; margin-left: auto; margin-right: auto; cursor: pointer;">
              <input type="checkbox" id="srgbGamma" style="margin: 0;">
              <span>sRGB Gamma Decoding</span>
            </label>
          </div>

        <select id="colormapSelect" style="display: none;">
          <option value="grayscale">Grayscale (default)</option>
          <option value="viridis">Viridis</option>
          <option value="plasma">Plasma</option>
          <option value="inferno">Inferno</option>
          <option value="magma">Magma</option>
          <option value="jet">Jet (rainbow)</option>
          <option value="hot">Hot</option>
          <option value="cool">Cool</option>
          <option value="parula">Parula</option>
          <option value="roseus">Roseus</option>
        </select>
        </div>
      </div>

      <div class="row">
        <label id="dynRangeLabel" style="cursor:pointer" title="Double-click to reset">Dynamic Range (dB) <input type="number" id="dynRange" value="40" min="10" max="140" step="1"></label>
        <label>Noise Floor (dB) <input type="number" id="lowFloorDb" value="40" min="20" max="120" step="1"></label>
      </div>

      <div class="row">
        <label id="freqScaleLabel" style="cursor:pointer" title="Double-click to reset">Frequency Scale <select id="freqScale"><option value="linear" selected>Linear</option><option value="log">Log</option><option value="mel">Mel</option><option value="bark">Bark</option></select></label>
        <label id="melTypeLabel" title="Mel formula type - Slaney is used by librosa/NVIDIA">Mel Type <select id="melType"><option value="htk">HTK</option><option value="slaney" selected>Slaney (librosa)</option></select></label>
        <label id="minFreqLabel" style="cursor:pointer" title="Double-click to reset">Min Frequency (Hz) <input type="number" id="minFreq" value="0" step="1"></label>
        <label id="maxFreqLabel" style="cursor:pointer" title="Double-click to reset">Max Frequency (Hz) <input type="number" id="maxFreq" value="4500" step="1"></label>
      </div>

      <div class="row">
        <label id="assumedDurationLabel">Duration (sec) <input type="number" id="assumedDurationSec" value="1.0" step="0.1" min="0.1" style="padding:4px 8px; border-radius:6px; width:90px;"></label>
        <label id="sampleRateLabel" style="cursor:pointer" title="Double-click to reset">Sample Rate (Hz) <input type="number" id="sampleRate" value="48000" min="8000" max="192000" step="1000"></label>
        <label id="fftSizeLabel" style="cursor:pointer" title="Double-click to reset">FFT Size <select id="fftSize"><option value="256">256</option><option value="512">512</option><option value="1024">1024</option><option value="2048" selected>2048</option><option value="4096">4096</option><option value="8192">8192</option><option value="16384">16384</option></select></label>
      </div>

      <div class="row">
        <label>Phase Method
          <select id="phaseMethod">
            <option value="griffinlim" selected>Griffin-Lim (FGLA)</option>
            <option value="pghi_true">PGHI</option>
            <option value="istft">Zero Phase</option>
            <option value="running">Additive Synthesis</option>
            <option value="neural">Neural Vocoder</option>
          </select>
        </label>
        <label id="iterationsLabel">Iterations <input type="number" id="iterations" value="24" min="1" max="50" step="1"></label>
      </div>
      <div class="row" id="neuralVocoderOptions" style="display: none;">
        <label style="flex: 1;">Vocoder Model URL <input type="text" id="vocoderModelUrl" placeholder="Enter ONNX model URL" style="width: 100%;"></label>
        <label>Model Sample Rate <input type="number" id="vocoderSampleRate" value="22050" min="8000" max="48000" step="1" style="width: 100px;"></label>
        <button id="loadVocoderBtn" style="white-space: nowrap;">Load Model</button>
      </div>

    </div>

    <!-- SECTION: Pre/Post-Processing (Optional) -->
    <div class="control-section">
      <h3>‚öôÔ∏è PRE/POST-PROCESSING (OPTIONAL)</h3>
      <div class="row">
        <label>Pre-Gain <input type="number" id="preGainSlider" min="0.1" max="10.0" step="0.1" value="1.0"></label>
        <label>Post-Gain <input type="number" id="postGainSlider" min="0.1" max="10.0" step="0.1" value="1.0"></label>
        <label style="display: flex; flex-direction: row; align-items: center; gap: 8px;"><input type="checkbox" id="reverseCheckbox">Reverse Audio</label>
      </div>
      <div class="row">
        <label style="display: flex; flex-direction: row; align-items: center; gap: 8px;">
          <input type="checkbox" id="interpolateFrames">Interpolate Frames
        </label>
        <label>Target Overlap % <input type="number" id="targetOverlap" value="75" min="50" max="87.5" step="12.5" style="width: 80px;"></label>
        <label style="display: flex; flex-direction: row; align-items: center; gap: 8px;" title="Smooth magnitude across time to reduce warble from quantization">
          <input type="checkbox" id="smoothMagnitude">Pre-smooth Spectrogram
        </label>
      </div>
      <div class="row">
        <label style="display: flex; flex-direction: row; align-items: center; gap: 8px;"><input type="checkbox" id="applyRolloff">High-end Roll-off</label>
        <label style="display: flex; flex-direction: row; align-items: center; gap: 8px;"><input type="checkbox" id="applySmoothTime">Temporal Smoothing (3-col)</label>
      </div>
    </div>
  </div>

  <div class="controls">
    <div class="control-section">
      <h3>üéµ INVERTED AUDIO</h3>
      <!-- Volume Warning -->
      <div style="width: 90vw; max-width: 700px; background: rgba(248, 149, 64, 0.15); border: 1px solid #f89540; border-radius: 8px; padding: 12px 16px; margin: 10px 0; text-align: center;">
        <span style="color: #f89540; font-weight: 600;">WARNING:</span>
        <span style="color: var(--ink); font-size: 13px; font-weight: 600;"> Lower your volume before processing. Inversion may produce unexpectedly loud output.</span>
      </div>
  
      
      <!-- Action Buttons -->
      <div class="row" style="margin-top: 20px;">
        <button id="invertBtn" type="button">Invert Spectrogram</button>
        <button id="downloadBtn" type="button" style="display:none">Download Audio</button>
      </div>
    </div>

    <div class="debug" id="log">Ready.</div>

    <!-- Audio player positioned directly above playhead canvas for perfect correlation -->
    <audio id="audioPlayer" controls style="margin: 10px 0;"></audio>

    <!-- Main canvas with playhead - directly below audio controls -->
    <div class="canvas-container" id="canvasContainer">
      <canvas id="canvas"></canvas>
      <div class="playhead" id="playhead"></div>
      <div class="playhead-tooltip" id="playheadTooltip">0:00.000</div>
    </div>
  </div>

  <script>
    // ============================================
    // COLORMAP RADIO BUTTON HANDLER
    // ============================================
    (function initColormapRadios() {
      const radios = document.querySelectorAll('input[name="colormap"]');
      const hiddenSelect = document.getElementById('colormapSelect');
      
      radios.forEach(radio => {
        radio.addEventListener('change', (e) => {
          if (e.target.checked) {
            // Update hidden select to maintain existing functionality
            hiddenSelect.value = e.target.value;
            
            // Trigger change event on the hidden select
            const event = new Event('change', { bubbles: true });
            hiddenSelect.dispatchEvent(event);
          }
        });
      });
    })();

    // ============================================
    // NEURAL VOCODER UI HANDLER
    // ============================================
    (function initNeuralVocoderUI() {
      const phaseMethodSelect = document.getElementById('phaseMethod');
      const neuralOptions = document.getElementById('neuralVocoderOptions');
      const loadVocoderBtn = document.getElementById('loadVocoderBtn');
      const vocoderModelUrl = document.getElementById('vocoderModelUrl');

      const iterationsLabel = document.getElementById('iterationsLabel');

      function updatePhaseMethodUI() {
        // Show/hide neural vocoder options
        if (phaseMethodSelect.value === 'neural') {
          neuralOptions.style.display = 'flex';
        } else {
          neuralOptions.style.display = 'none';
        }

        // Show/hide iterations (for GL-based methods)
        const usesGL = phaseMethodSelect.value === 'griffinlim';
        if (iterationsLabel) {
          iterationsLabel.style.display = usesGL ? '' : 'none';
        }
      }

      phaseMethodSelect.addEventListener('change', updatePhaseMethodUI);
      updatePhaseMethodUI(); // Initial state

      // Load model button handler
      if (loadVocoderBtn) {
        loadVocoderBtn.addEventListener('click', async () => {
          const url = vocoderModelUrl.value.trim();
          if (!url) {
            alert('Please enter a vocoder model URL. You can use a MelGAN or HiFi-GAN ONNX model.');
            return;
          }

          const logEl = document.getElementById('log');
          const log = (msg) => {
            if (logEl) logEl.textContent = msg;
          };

          loadVocoderBtn.disabled = true;
          loadVocoderBtn.textContent = 'Loading...';

          const success = await loadVocoderModel(url, log);

          if (success) {
            loadVocoderBtn.textContent = 'Model Loaded ‚úì';
            loadVocoderBtn.style.backgroundColor = 'green';
          } else {
            loadVocoderBtn.textContent = 'Load Failed';
            loadVocoderBtn.disabled = false;
          }
        });
      }
    })();

    // ============================================
    // MAIN APPLICATION CODE
    // ============================================
    const canvas = document.getElementById('canvas');
    const canvasContainer = document.getElementById('canvasContainer');
    const thumbnail = document.getElementById('thumbnail');
    const thumbnailCtx = thumbnail.getContext('2d', { colorSpace:'srgb' });
    const ctx = canvas.getContext('2d', { willReadFrequently:true, colorSpace:'srgb' });
    ctx.imageSmoothingEnabled = false;

    // Diagnostic: Check if colorSpace is actually supported
    const actualColorSpace = ctx.getContextAttributes?.()?.colorSpace;
    console.log('[COLOR SPACE] Requested: srgb, Actual:', actualColorSpace || 'not supported/unknown');
    if (!actualColorSpace || actualColorSpace !== 'srgb') {
      console.warn('[COLOR SPACE] Mobile browser may not support colorSpace option - color interpretation may differ!');
    }

    // Update thumbnail preview
    function updateThumbnail() {
      if (!canvas.width || !canvas.height) return;

      // Calculate thumbnail size maintaining aspect ratio
      const maxWidth = 300;
      const maxHeight = 150;
      const aspectRatio = canvas.width / canvas.height;

      let thumbWidth, thumbHeight;
      if (aspectRatio > maxWidth / maxHeight) {
        // Width-constrained
        thumbWidth = maxWidth;
        thumbHeight = maxWidth / aspectRatio;
      } else {
        // Height-constrained
        thumbHeight = maxHeight;
        thumbWidth = maxHeight * aspectRatio;
      }

      thumbnail.width = thumbWidth;
      thumbnail.height = thumbHeight;
      thumbnailCtx.imageSmoothingEnabled = true;
      thumbnailCtx.drawImage(canvas, 0, 0, thumbWidth, thumbHeight);
      thumbnail.style.display = 'block';
    }

    // Smart canvas scaling: scale to fit if reasonable aspect ratio, otherwise use scrollbars
    function scaleCanvasDisplay() {
      if (!canvas.width || !canvas.height) return;

      const containerWidth = canvasContainer.clientWidth;
      const aspectRatio = canvas.width / canvas.height;

      // If aspect ratio is reasonable (not too wide), scale to fit container width
      // Otherwise, limit scaling to prevent tiny display and use scrollbars
      const maxAspectRatio = 10; // If wider than 10:1, don't scale down fully
      const minScale = 0.3; // Never scale below 30% of original size

      let scale = 1;

      if (aspectRatio <= maxAspectRatio) {
        // Reasonable aspect ratio - scale to fit container width
        scale = Math.min(1, containerWidth / canvas.width);
      } else {
        // Very wide image - use limited scaling and let scrollbars handle it
        scale = Math.max(minScale, containerWidth / (canvas.width * 0.5));
      }

      // Apply CSS transform for visual scaling (doesn't affect pixel data)
      canvas.style.width = `${canvas.width * scale}px`;
      canvas.style.height = `${canvas.height * scale}px`;

      console.log(`[CANVAS SCALE] Dimensions: ${canvas.width}x${canvas.height}, Aspect: ${aspectRatio.toFixed(2)}, Scale: ${(scale * 100).toFixed(0)}%`);
    }

    // Rescale on window resize
    let resizeTimeout;
    window.addEventListener('resize', () => {
      clearTimeout(resizeTimeout);
      resizeTimeout = setTimeout(scaleCanvasDisplay, 150);
    });

    // ============================================
    // PLAYHEAD FUNCTIONALITY
    // ============================================
    const playhead = document.getElementById('playhead');
    const playheadTooltip = document.getElementById('playheadTooltip');
    let audioElement = null; // Will be set when audio is generated
    let audioDuration = 0;
    let pixelsPerSecond = 1; // Will be updated after reconstruction
    let isDragging = false;
    let autoScrollInterval = null;

    // Format time as M:SS.mmm
    function formatTime(seconds) {
      const mins = Math.floor(seconds / 60);
      const secs = Math.floor(seconds % 60);
      const ms = Math.floor((seconds % 1) * 1000);
      return `${mins}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(3, '0')}`;
    }

    // Convert canvas pixel X position to audio time
    function pixelToTime(px) {
      return px / pixelsPerSecond;
    }

    // Convert audio time to canvas pixel X position
    function timeToPixel(time) {
      return time * pixelsPerSecond;
    }

    // Update playhead visual position
    function updatePlayheadPosition(time) {
      if (!audioElement || !audioDuration) return;

      const px = timeToPixel(time);
      const scale = parseFloat(canvas.style.width) / canvas.width || 1;
      const visualPx = px * scale;

      playhead.style.left = `${visualPx}px`;
      playhead.style.display = 'block';
    }

    // Update playhead during audio playback
    function onAudioTimeUpdate() {
      if (!isDragging && audioElement) {
        updatePlayheadPosition(audioElement.currentTime);
      }
    }

    // Seek audio to specific time
    function seekAudio(time) {
      if (!audioElement) {
        console.warn('[PLAYHEAD] Cannot seek: audioElement is null');
        return;
      }
      if (!audioDuration) {
        console.warn('[PLAYHEAD] Cannot seek: audioDuration is 0');
        return;
      }
      const seekTime = Math.max(0, Math.min(time, audioDuration));
      console.log(`[PLAYHEAD] Seeking to ${seekTime.toFixed(3)}s (duration: ${audioDuration.toFixed(3)}s)`);
      audioElement.currentTime = seekTime;
    }

    // Get mouse/touch position relative to canvas (in canvas pixel coordinates)
    function getCanvasPosition(clientX) {
      const rect = canvas.getBoundingClientRect();
      const scale = parseFloat(canvas.style.width) / canvas.width || 1;
      const visualX = clientX - rect.left;
      const canvasX = visualX / scale;
      console.log(`[PLAYHEAD] Click at clientX=${clientX}, canvasX=${canvasX.toFixed(1)}, scale=${scale.toFixed(3)}`);
      return canvasX;
    }

    // Auto-scroll container when dragging near edges
    function startAutoScroll(direction) {
      stopAutoScroll();
      autoScrollInterval = setInterval(() => {
        const scrollAmount = direction * 10;
        canvasContainer.scrollLeft += scrollAmount;
      }, 16);
    }

    function stopAutoScroll() {
      if (autoScrollInterval) {
        clearInterval(autoScrollInterval);
        autoScrollInterval = null;
      }
    }

    // Handle seeking (click or drag)
    function handleSeek(clientX, showTooltip = false) {
      const canvasX = getCanvasPosition(clientX);
      const time = pixelToTime(canvasX);

      updatePlayheadPosition(time);
      seekAudio(time);

      if (showTooltip) {
        const rect = canvas.getBoundingClientRect();
        playheadTooltip.textContent = formatTime(time);
        playheadTooltip.style.left = `${clientX - rect.left}px`;
        playheadTooltip.style.top = '10px';
        playheadTooltip.style.display = 'block';
      }

      // Auto-scroll detection
      const containerRect = canvasContainer.getBoundingClientRect();
      const edgeThreshold = 50;
      const relativeX = clientX - containerRect.left;

      if (relativeX < edgeThreshold) {
        startAutoScroll(-1); // Scroll left
      } else if (relativeX > containerRect.width - edgeThreshold) {
        startAutoScroll(1); // Scroll right
      } else {
        stopAutoScroll();
      }
    }

    // Mouse/Touch event handlers
    canvas.addEventListener('mousedown', (e) => {
      if (!audioElement) return;
      isDragging = true;
      playhead.classList.add('dragging');
      handleSeek(e.clientX, true);
      e.preventDefault();
    });

    canvas.addEventListener('touchstart', (e) => {
      if (!audioElement || e.touches.length !== 1) return;
      isDragging = true;
      playhead.classList.add('dragging');
      handleSeek(e.touches[0].clientX, true);
      e.preventDefault();
    });

    document.addEventListener('mousemove', (e) => {
      if (isDragging) {
        handleSeek(e.clientX, true);
      }
    });

    document.addEventListener('touchmove', (e) => {
      if (isDragging && e.touches.length === 1) {
        handleSeek(e.touches[0].clientX, true);
        e.preventDefault();
      }
    });

    document.addEventListener('mouseup', () => {
      if (isDragging) {
        isDragging = false;
        playhead.classList.remove('dragging');
        playheadTooltip.style.display = 'none';
        stopAutoScroll();
      }
    });

    document.addEventListener('touchend', () => {
      if (isDragging) {
        isDragging = false;
        playhead.classList.remove('dragging');
        playheadTooltip.style.display = 'none';
        stopAutoScroll();
      }
    });

    const __SRGB_TO_LINEAR = new Float32Array(256);
    (function buildSRGBLUT(){
      for(let i=0;i<256;i++){
        const cs = i / 255;
        __SRGB_TO_LINEAR[i] = (cs <= 0.04045) ? (cs / 12.92) : Math.pow((cs + 0.055) / 1.055, 2.4);
      }
    })();
    
    function srgb8ToLinear01(u8){
      return __SRGB_TO_LINEAR[(u8 & 255) >>> 0];
    }

    const logEl = document.getElementById('log');
    
    function log(m){
      const msg = String(m).replace(/\\n/g, '\n');
      if(logEl.textContent && !logEl.textContent.endsWith('\n')) logEl.textContent += '\n';
      logEl.textContent += msg;
      logEl.scrollTop = logEl.scrollHeight;
    }
    
    function setStatus(m){
      const msg = String(m).replace(/\\n/g, '\n');
      logEl.textContent = msg;
      logEl.scrollTop = logEl.scrollHeight;
    }
    
    function yieldUI(){ return new Promise(r=>requestAnimationFrame(r)); }

    // Internal normalization factor so Pre-Gain=1.0 produces reasonable output levels.
    // The iSTFT requires magnitude scaling by N/2 (specScale), which would cause massive
    // clipping if Pre-Gain were applied directly. This constant absorbs that so users
    // can think of Pre-Gain as a simple multiplier: 1.0 = baseline, 2.0 = double, etc.
    const PRE_GAIN_NORMALIZATION = 0.05;

    function __getPreGain(){
      const el = document.getElementById('preGainSlider');
      const v = el ? parseFloat(el.value) : 1.0;
      const userGain = Number.isFinite(v) ? v : 1.0;
      return userGain * PRE_GAIN_NORMALIZATION;
    }

    function isPow2(n){ return n>0 && (n & (n-1))===0; }

    function nearestPow2(n){
      if(!isFinite(n) || n<=0) return 2048;
      let p = 1;
      while(p<n) p<<=1;
      const lower = p>>1;
      if(lower===0) return p;
      return (n-lower <= p-n)? lower : p;
    }

    function enforceFFTInput(){
      const el = document.getElementById('fftSize');
      if(!el) return;
      const raw = parseInt(el.value, 10);
      if(!isPow2(raw)){
        const fixed = nearestPow2(raw);
        el.value = String(fixed);
        if(typeof log === 'function') log(`FFT size must be a power of two. Adjusted to ${fixed}.`);
      }
    }

    let __nanWarned = false;

    function anyBad(arr){
      if(!arr) return false;
      for(let i=0;i<arr.length;i++){
        const v = arr[i];
        if(!Number.isFinite(v) || Number.isNaN(v)) return true;
      }
      return false;
    }

    function warnNaNs(stage, notes){
      if(__nanWarned) return;
      __nanWarned = true;
      const tips = [
        "Confirm px/sec is nonzero and matches the PNG time scale.",
        "Ensure minFreq is less than maxFreq and crop height matches the image rows.",
        "Try a smaller dynRange.",
        "Use an FFT size that is a power of 2 and not much larger than about 2 times the crop height.",
        "If using GL or PGHI, try fewer iterations to isolate issues.",
        "Use dB offset 0 and make sure the sample rate matches the source."
      ].join("\\n");
      log(`Warning: invalid numeric values detected at ${stage}.\\n${notes||""}\\nHints:\\n${tips}`);
    }

    // Double-click-to-reset handlers
    (function(){
      const cropLab = document.getElementById('cropHeightLabel');
      const cropInp = document.getElementById('cropHeight');
      if(cropLab && cropInp){
        cropLab.ondblclick = ()=>{
          try{
            const h = document.getElementById('canvas')?.height;
            if(h && h>0){ cropInp.value = String(h); }
          }catch(_e){}
        };
      }

      const srLab = document.getElementById('sampleRateLabel');
      const srInp = document.getElementById('sampleRate');
      if(srLab && srInp){
        srLab.ondblclick = ()=>{
          const sr = Number(window.__lastMeta?.sampleRate);
          if(Number.isFinite(sr) && sr>0){ srInp.value = String(sr|0); }
        };
      }

      const fftLab = document.getElementById('fftSizeLabel');
      const fftSel = document.getElementById('fftSize');
      if(fftLab && fftSel){
        fftLab.ondblclick = ()=>{
          const n = Number(window.__lastMeta?.fftSize);
          if(Number.isFinite(n) && n>0){
            let v = String(n|0);
            const options = Array.from(fftSel.options).map(o=>o.value);
            if(!options.includes(v)){
              const pow2 = (x)=> x>0 && (x & (x-1))===0;
              let m = n;
              if(!pow2(m)){ let p=1; while(p<m) p<<=1; const lo=p>>1; m = (m-lo<=p-m)? lo : p; }
              v = String(m);
              if(!options.includes(v)){
                const opt = document.createElement('option'); opt.value=v; opt.textContent=v; fftSel.appendChild(opt);
              }
            }
            fftSel.value = v;
          }
        };
      }

      const minFreqLab = document.getElementById('minFreqLabel');
      const minFreqInp = document.getElementById('minFreq');
      if(minFreqLab && minFreqInp){
        minFreqLab.ondblclick = ()=>{
          const v = Number(window.__lastMeta?.minHz);
          if(Number.isFinite(v) && v>=0){ minFreqInp.value = String(v); }
        };
      }

      const maxFreqLab = document.getElementById('maxFreqLabel');
      const maxFreqInp = document.getElementById('maxFreq');
      if(maxFreqLab && maxFreqInp){
        maxFreqLab.ondblclick = ()=>{
          const v = Number(window.__lastMeta?.maxHz);
          if(Number.isFinite(v) && v>0){ maxFreqInp.value = String(v); }
        };
      }

      const dynRangeLab = document.getElementById('dynRangeLabel');
      const dynRangeInp = document.getElementById('dynRange');
      if(dynRangeLab && dynRangeInp){
        dynRangeLab.ondblclick = ()=>{
          const v = Number(window.__lastMeta?.dynRange);
          if(Number.isFinite(v) && v>0){ dynRangeInp.value = String(v); }
        };
      }

      const invertColorsEl = document.getElementById('invertColorsIn');
      const invertColorsLab = invertColorsEl ? invertColorsEl.parentElement : null;
      if(invertColorsEl && invertColorsLab){
        invertColorsLab.ondblclick = ()=>{
          const m = window.__lastMeta || {};
          const v = (m.invertColors!=null) ? String(m.invertColors).toLowerCase() : null;
          if(v===null) return;
          invertColorsEl.checked = (v==='1'||v==='true');
        };
      }

      const freqScaleLab = document.getElementById('freqScaleLabel');
      const freqScaleSel = document.getElementById('freqScale');
      const melTypeLab = document.getElementById('melTypeLabel');

      // Global function to show/hide Mel Type based on frequency scale
      // Called when scale changes or when metadata is loaded
      window.updateMelTypeVisibility = function() {
        if(melTypeLab) {
          melTypeLab.style.display = (freqScaleSel?.value === 'mel') ? '' : 'none';
        }
      };

      if(freqScaleLab && freqScaleSel){
        freqScaleLab.ondblclick = ()=>{
          const meta = window.__lastMeta || {};
          const v = (meta.freqScale || meta.scale);
          if(v && (v==='linear' || v==='log' || v==='mel' || v==='bark')) {
            freqScaleSel.value = v;
            window.updateMelTypeVisibility();
          }
        };
        freqScaleSel.addEventListener('change', window.updateMelTypeVisibility);
        window.updateMelTypeVisibility(); // Initial state
      }
    })();

    document.getElementById('invertBtn').addEventListener('click', processImage);

    // ============================================
    // COLORMAP CONVERSION FUNCTIONS
    // ============================================
    // Build gradient from key colors (matching SpectroGhost's method)
    function buildGradientArray(colors) {
      const result = [];
      const n = colors.length - 1;
      for(let i = 0; i < 256; i++) {
        const t = (i / 255);
        const s = t * n;
        const idx = Math.min(Math.floor(s), n - 1);
        const frac = s - idx;
        const c0 = colors[idx];
        const c1 = colors[idx + 1];
        const r = Math.round(c0[0] + (c1[0] - c0[0]) * frac);
        const g = Math.round(c0[1] + (c1[1] - c0[1]) * frac);
        const b = Math.round(c0[2] + (c1[2] - c0[2]) * frac);
        result.push([r, g, b]);
      }
      return result;
    }

    // Build colormap array from normalized 0-1 RGB data
    function buildFromNormalizedData(data) {
      const result = [];
      for(let i = 0; i < 256; i++) {
        const rgb = data[i];
        result.push([
          Math.round(rgb[0] * 255),
          Math.round(rgb[1] * 255),
          Math.round(rgb[2] * 255)
        ]);
      }
      return result;
    }

    // Roseus colormap data (perceptually uniform, from https://github.com/dofuuz/roseus)
    const ROSEUS_DATA = [
      [0.004528,0.004341,0.004307],[0.005625,0.006156,0.006010],[0.006628,0.008293,0.008161],[0.007551,0.010738,0.010790],
      [0.008382,0.013482,0.013941],[0.009111,0.016520,0.017662],[0.009727,0.019846,0.022009],[0.010223,0.023452,0.027035],
      [0.010593,0.027331,0.032799],[0.010833,0.031475,0.039361],[0.010941,0.035875,0.046415],[0.010918,0.040520,0.053597],
      [0.010768,0.045158,0.060914],[0.010492,0.049708,0.068367],[0.010098,0.054171,0.075954],[0.009594,0.058549,0.083672],
      [0.008989,0.062840,0.091521],[0.008297,0.067046,0.099499],[0.007530,0.071165,0.107603],[0.006704,0.075196,0.115830],
      [0.005838,0.079140,0.124178],[0.004949,0.082994,0.132643],[0.004062,0.086758,0.141223],[0.003198,0.090430,0.149913],
      [0.002382,0.094010,0.158711],[0.001643,0.097494,0.167612],[0.001009,0.100883,0.176612],[0.000514,0.104174,0.185704],
      [0.000187,0.107366,0.194886],[0.000066,0.110457,0.204151],[0.000186,0.113445,0.213496],[0.000587,0.116329,0.222914],
      [0.001309,0.119106,0.232397],[0.002394,0.121776,0.241942],[0.003886,0.124336,0.251542],[0.005831,0.126784,0.261189],
      [0.008276,0.129120,0.270876],[0.011268,0.131342,0.280598],[0.014859,0.133447,0.290345],[0.019100,0.135435,0.300111],
      [0.024043,0.137305,0.309888],[0.029742,0.139054,0.319669],[0.036252,0.140683,0.329441],[0.043507,0.142189,0.339203],
      [0.050922,0.143571,0.348942],[0.058432,0.144831,0.358649],[0.066041,0.145965,0.368319],[0.073744,0.146974,0.377938],
      [0.081541,0.147858,0.387501],[0.089431,0.148616,0.396998],[0.097411,0.149248,0.406419],[0.105479,0.149754,0.415755],
      [0.113634,0.150134,0.424998],[0.121873,0.150389,0.434139],[0.130192,0.150521,0.443167],[0.138591,0.150528,0.452075],
      [0.147065,0.150413,0.460852],[0.155614,0.150175,0.469493],[0.164232,0.149818,0.477985],[0.172917,0.149343,0.486322],
      [0.181666,0.148751,0.494494],[0.190476,0.148046,0.502493],[0.199344,0.147229,0.510313],[0.208267,0.146302,0.517944],
      [0.217242,0.145267,0.525380],[0.226264,0.144131,0.532613],[0.235331,0.142894,0.539635],[0.244440,0.141559,0.546442],
      [0.253587,0.140131,0.553026],[0.262769,0.138615,0.559381],[0.271981,0.137016,0.565500],[0.281222,0.135335,0.571381],
      [0.290487,0.133581,0.577017],[0.299774,0.131757,0.582404],[0.309080,0.129867,0.587538],[0.318399,0.127920,0.592415],
      [0.327730,0.125921,0.597032],[0.337069,0.123877,0.601385],[0.346413,0.121793,0.605474],[0.355758,0.119678,0.609295],
      [0.365102,0.117540,0.612846],[0.374443,0.115386,0.616127],[0.383774,0.113226,0.619138],[0.393096,0.111066,0.621876],
      [0.402404,0.108918,0.624343],[0.411694,0.106794,0.626540],[0.420967,0.104698,0.628466],[0.430217,0.102645,0.630123],
      [0.439442,0.100647,0.631513],[0.448637,0.098717,0.632638],[0.457805,0.096861,0.633499],[0.466940,0.095095,0.634100],
      [0.476040,0.093433,0.634443],[0.485102,0.091885,0.634532],[0.494125,0.090466,0.634370],[0.503104,0.089190,0.633962],
      [0.512041,0.088067,0.633311],[0.520931,0.087108,0.632420],[0.529773,0.086329,0.631297],[0.538564,0.085738,0.629944],
      [0.547302,0.085346,0.628367],[0.555986,0.085162,0.626572],[0.564615,0.085190,0.624563],[0.573187,0.085439,0.622345],
      [0.581698,0.085913,0.619926],[0.590149,0.086615,0.617311],[0.598538,0.087543,0.614503],[0.606862,0.088700,0.611511],
      [0.615120,0.090084,0.608343],[0.623312,0.091690,0.605001],[0.631438,0.093511,0.601489],[0.639492,0.095546,0.597821],
      [0.647476,0.097787,0.593999],[0.655389,0.100226,0.590028],[0.663230,0.102856,0.585914],[0.670995,0.105669,0.581667],
      [0.678686,0.108658,0.577291],[0.686302,0.111813,0.572790],[0.693840,0.115129,0.568175],[0.701300,0.118597,0.563449],
      [0.708682,0.122209,0.558616],[0.715984,0.125959,0.553687],[0.723206,0.129840,0.548666],[0.730346,0.133846,0.543558],
      [0.737406,0.137970,0.538366],[0.744382,0.142209,0.533101],[0.751274,0.146556,0.527767],[0.758082,0.151008,0.522369],
      [0.764805,0.155559,0.516912],[0.771443,0.160206,0.511402],[0.777995,0.164946,0.505845],[0.784459,0.169774,0.500246],
      [0.790836,0.174689,0.494607],[0.797125,0.179688,0.488935],[0.803325,0.184767,0.483238],[0.809435,0.189925,0.477518],
      [0.815455,0.195160,0.471781],[0.821384,0.200471,0.466028],[0.827222,0.205854,0.460267],[0.832968,0.211308,0.454505],
      [0.838621,0.216834,0.448738],[0.844181,0.222428,0.442979],[0.849647,0.228090,0.437230],[0.855019,0.233819,0.431491],
      [0.860295,0.239613,0.425771],[0.865475,0.245471,0.420074],[0.870558,0.251393,0.414403],[0.875545,0.257380,0.408759],
      [0.880433,0.263427,0.403152],[0.885223,0.269535,0.397585],[0.889913,0.275705,0.392058],[0.894503,0.281934,0.386578],
      [0.898993,0.288222,0.381152],[0.903381,0.294569,0.375781],[0.907667,0.300974,0.370469],[0.911849,0.307435,0.365223],
      [0.915928,0.313953,0.360048],[0.919902,0.320527,0.354948],[0.923771,0.327155,0.349928],[0.927533,0.333838,0.344994],
      [0.931188,0.340576,0.340149],[0.934736,0.347366,0.335403],[0.938175,0.354207,0.330762],[0.941504,0.361101,0.326229],
      [0.944723,0.368045,0.321814],[0.947831,0.375039,0.317523],[0.950826,0.382083,0.313364],[0.953709,0.389175,0.309345],
      [0.956478,0.396314,0.305477],[0.959133,0.403499,0.301766],[0.961671,0.410731,0.298221],[0.964093,0.418008,0.294853],
      [0.966399,0.425327,0.291676],[0.968586,0.432690,0.288696],[0.970654,0.440095,0.285926],[0.972603,0.447540,0.283380],
      [0.974431,0.455025,0.281067],[0.976139,0.462547,0.279003],[0.977725,0.470107,0.277198],[0.979188,0.477703,0.275666],
      [0.980529,0.485332,0.274422],[0.981747,0.492995,0.273476],[0.982840,0.500690,0.272842],[0.983808,0.508415,0.272532],
      [0.984653,0.516168,0.272560],[0.985373,0.523948,0.272937],[0.985966,0.531754,0.273673],[0.986436,0.539582,0.274779],
      [0.986780,0.547434,0.276264],[0.986998,0.555305,0.278135],[0.987091,0.563195,0.280401],[0.987061,0.571100,0.283066],
      [0.986907,0.579019,0.286137],[0.986629,0.586950,0.289615],[0.986229,0.594891,0.293503],[0.985709,0.602839,0.297802],
      [0.985069,0.610792,0.302512],[0.984310,0.618748,0.307632],[0.983435,0.626704,0.313159],[0.982445,0.634657,0.319089],
      [0.981341,0.642606,0.325420],[0.980130,0.650546,0.332144],[0.978812,0.658475,0.339257],[0.977392,0.666391,0.346753],
      [0.975870,0.674290,0.354625],[0.974252,0.682170,0.362865],[0.972545,0.690026,0.371466],[0.970750,0.697856,0.380419],
      [0.968873,0.705658,0.389718],[0.966921,0.713426,0.399353],[0.964901,0.721157,0.409313],[0.962815,0.728851,0.419594],
      [0.960677,0.736500,0.430181],[0.958490,0.744103,0.441070],[0.956263,0.751656,0.452248],[0.954009,0.759153,0.463702],
      [0.951732,0.766595,0.475429],[0.949445,0.773974,0.487414],[0.947158,0.781289,0.499647],[0.944885,0.788535,0.512116],
      [0.942634,0.795709,0.524811],[0.940423,0.802807,0.537717],[0.938261,0.809825,0.550825],[0.936163,0.816760,0.564121],
      [0.934146,0.823608,0.577591],[0.932224,0.830366,0.591220],[0.930412,0.837031,0.604997],[0.928727,0.843599,0.618904],
      [0.927187,0.850066,0.632926],[0.925809,0.856432,0.647047],[0.924610,0.862691,0.661249],[0.923607,0.868843,0.675517],
      [0.922820,0.874884,0.689832],[0.922265,0.880812,0.704174],[0.921962,0.886626,0.718523],[0.921930,0.892323,0.732859],
      [0.922183,0.897903,0.747163],[0.922741,0.903364,0.761410],[0.923620,0.908706,0.775580],[0.924837,0.913928,0.789648],
      [0.926405,0.919031,0.803590],[0.928340,0.924015,0.817381],[0.930655,0.928881,0.830995],[0.933360,0.933631,0.844405],
      [0.936466,0.938267,0.857583],[0.939982,0.942791,0.870499],[0.943914,0.947207,0.883122],[0.948267,0.951519,0.895421],
      [0.953044,0.955732,0.907359],[0.958246,0.959852,0.918901],[0.963869,0.963887,0.930004],[0.969909,0.967845,0.940623],
      [0.976355,0.971737,0.950704],[0.983195,0.975580,0.960181],[0.990402,0.979395,0.968966],[0.997930,0.983217,0.976920]
    ];

    const COLORMAP_DATA = {
      grayscale: null, // handled specially in rgbToColormapValue
      viridis: buildGradientArray([[68,1,84],[59,82,139],[33,145,140],[94,201,98],[253,231,37]]),
      plasma: buildGradientArray([[13,8,135],[126,3,168],[204,71,120],[248,149,64],[240,249,33]]),
      inferno: buildGradientArray([[0,0,4],[66,10,104],[147,81,58],[221,81,10],[252,255,164]]),
      magma: buildGradientArray([[0,0,4],[59,15,112],[140,41,129],[222,73,104],[254,159,109],[252,253,191]]),
      jet: buildGradientArray([[0,0,127],[0,0,255],[0,255,255],[0,255,0],[255,255,0],[255,0,0],[127,0,0]]),
      hot: buildGradientArray([[0,0,0],[255,0,0],[255,255,0],[255,255,255]]),
      cool: buildGradientArray([[0,255,255],[255,0,255]]),
      parula: buildGradientArray([[53,42,135],[15,92,221],[0,166,255],[255,237,0],[255,77,0]]),
      roseus: buildFromNormalizedData(ROSEUS_DATA)
    };

    // Convert RGB colormap value to grayscale intensity (0-1)
    // This finds the closest colormap entry and returns its position in the gradient
    // If linearInput=true, skip sRGB gamma correction (for SpectroGhost images which write linear values)
    function rgbToColormapValue(r, g, b, colormapName, linearInput = false) {
      if(colormapName === 'grayscale') {
        if(linearInput) {
          // SpectroGhost writes linear values directly - no gamma correction needed
          return (0.299 * r + 0.587 * g + 0.114 * b) / 255;
        }
        // External images: Convert from sRGB gamma to linear, then calculate luminance
        const rLin = srgb8ToLinear01(r);
        const gLin = srgb8ToLinear01(g);
        const bLin = srgb8ToLinear01(b);
        return 0.299 * rLin + 0.587 * gLin + 0.114 * bLin;
      }

      const colormap = COLORMAP_DATA[colormapName];
      if(!colormap) return (0.299 * r + 0.587 * g + 0.114 * b) / 255;

      // Find closest colormap entry
      let minDist = Infinity;
      let bestIdx = 0;

      for(let i = 0; i < colormap.length; i++) {
        const [cr, cg, cb] = colormap[i];
        const dr = r - cr;
        const dg = g - cg;
        const db = b - cb;
        const dist = dr*dr + dg*dg + db*db;

        if(dist < minDist) {
          minDist = dist;
          bestIdx = i;
        }
      }

      // Return normalized position in colormap (0-1)
      return 1.0 - bestIdx / (colormap.length - 1);
    }

    

function _bilinearSampleGray(u8, w, h, fx, fy, colormapName, linearInput){
  const x0 = Math.max(0, Math.min(w-1, Math.floor(fx)));
  const y0 = Math.max(0, Math.min(h-1, Math.floor(fy)));
  const x1 = Math.min(w-1, x0+1);
  const y1 = Math.min(h-1, y0+1);
  const tx = fx - x0;
  const ty = fy - y0;
  const i00 = (y0*w + x0)*4;
  const i10 = (y0*w + x1)*4;
  const i01 = (y1*w + x0)*4;
  const i11 = (y1*w + x1)*4;
  
  // Sample RGB values
  const r00 = u8[i00], g00 = u8[i00+1], b00 = u8[i00+2];
  const r10 = u8[i10], g10 = u8[i10+1], b10 = u8[i10+2];
  const r01 = u8[i01], g01 = u8[i01+1], b01 = u8[i01+2];
  const r11 = u8[i11], g11 = u8[i11+1], b11 = u8[i11+2];
  
  // Interpolate RGB
  const r = r00 + (r10 - r00)*tx + (r01 - r00)*ty + (r11 - r01 - r10 + r00)*tx*ty;
  const g = g00 + (g10 - g00)*tx + (g01 - g00)*ty + (g11 - g01 - g10 + g00)*tx*ty;
  const b = b00 + (b10 - b00)*tx + (b01 - b00)*ty + (b11 - b01 - b10 + b00)*tx*ty;
  
  // Convert using colormap
  return rgbToColormapValue(r, g, b, colormapName || 'grayscale', linearInput) * 255;
}

function _resample2DGray(srcRGBA, srcW, srcH, dstW, dstH, colormapName, linearInput){
  const out = new Float32Array(dstW*dstH);
  const sx = (srcW - 1) / Math.max(1, dstW - 1);
  const sy = (srcH - 1) / Math.max(1, dstH - 1);
  for(let y=0;y<dstH;y++){
    const fy = y * sy;
    const rowOff = y*dstW;
    for(let x=0;x<dstW;x++){
      const fx = x * sx;
      out[rowOff + x] = _bilinearSampleGray(srcRGBA, srcW, srcH, fx, fy, colormapName, linearInput) / 255;
    }
  }
  return out;
}

async function processImage(){
      try{ enforceFFTInput(); }catch(_e){}
      const _fftEl = document.getElementById('fftSize');
      if(_fftEl){
        const _v = parseInt(_fftEl.value,10);
        if(!isPow2(_v)){
          log('FFT size must be a power of two. Please choose 256, 512, 1024, 2048, 4096, 8192 or 16384.');
          return;
        }
      }

      setStatus('Processing');
      const file = document.getElementById('imageInput').files[0];
      
      // Check if canvas has content (either from file or paste)
      if(!file && (canvas.width === 0 || canvas.height === 0)){ 
        alert('Please select or paste an image'); 
        return; 
      }
      
      const reverse = document.getElementById('reverseCheckbox').checked;
      const preGain = parseFloat(preGainSlider.value);

      const marginLeft = parseInt(document.getElementById('marginLeft').value,10) || 0;
      const cropHeight = parseInt(document.getElementById('cropHeight').value,10) || 192;
      const sampleRate = Math.max(4000, parseInt(document.getElementById('sampleRate').value,10) || 44100);
      const fftSize = Math.max(256, parseInt(document.getElementById('fftSize').value,10) || 1024);
      const minFreq = Math.max(0, parseFloat(document.getElementById('minFreq').value) || 0);
      const maxFreq = Math.max(minFreq+1, parseFloat(document.getElementById('maxFreq').value) || 4500);
      const dynRange = parseFloat(document.getElementById('dynRange').value) || 40;
      const phaseMethod = document.getElementById('phaseMethod').value;
      const iterations = Math.max(1, parseInt(document.getElementById('iterations').value,10) || 12);
      const applyFloor = document.getElementById('applyFloor')?.checked ?? true;
      const lowFloorDb = parseFloat(document.getElementById('lowFloorDb')?.value) || 60;
      const applySmoothTime = document.getElementById('applySmoothTime')?.checked ?? false;
      const applyRolloff = document.getElementById('applyRolloff')?.checked ?? false;

      // Function to process the canvas content
      const processCanvasContent = async () => {
        // Canvas already has the image (either from file load or paste), no need to redraw
        ctx.imageSmoothingEnabled = false;

        let cropWidth = Math.max(1, canvas.width - marginLeft);

        // Determine rows: prefer SpectroGhost metadata __height, then canvas.height, then cropHeight
        const hasMetadata = !!(window.__lastMeta && Object.keys(window.__lastMeta).length > 0);
        // Only trust __height if it's real SpectroGhost metadata (has fftSize AND hop)
        const isRealSpectroGhost = !!(window.__lastMeta?.fftSize && window.__lastMeta?.hop);
        // sRGB gamma checkbox is set from metadata at image-load time (applySpectroMeta),
        // not here ‚Äî so manual user changes survive re-renders.
        let rows;
        if (isRealSpectroGhost && window.__lastMeta?.__height && Number.isFinite(Number(window.__lastMeta.__height))) {
          // SpectroGhost metadata includes exact image height
          rows = Math.round(Number(window.__lastMeta.__height));
          log(`Using height from SpectroGhost metadata: ${rows}`);
        } else {
          // External image or no valid SpectroGhost metadata: use full canvas height
          rows = canvas.height;
          log(`Using canvas height: ${rows}`);
        }

        const marginBottom = 0;
        const y0 = Math.max(0, canvas.height - rows - marginBottom);

        // Debug logging for dimension issues
        log(`DEBUG: canvas.width=${canvas.width}, canvas.height=${canvas.height}, cropWidth=${cropWidth}, rows=${rows}, hasMetadata=${hasMetadata}`);

        // Duration and hop calculation
        let durationSec = 1.0;
        {
          const _d = document.getElementById('assumedDurationSec');
          if (_d && _d.value) {
            const v = Number(_d.value);
            if (Number.isFinite(v) && v > 0) durationSec = v;
          }
        }

        // Calculate hop - check if user changed duration from metadata, if so use user's duration
        let hop;
        let effPxPerSec;
        let actualDuration;

        // Check if user has manually changed the duration from what metadata set
        const metaDuration = window.__lastMeta?.duration_sec || window.__lastMeta?.durationSec || window.__lastMeta?.duration;
        const userChangedDuration = metaDuration && Math.abs(durationSec - Number(metaDuration)) > 0.001;

        // Use metadata hop only if user hasn't changed the duration
        if (!userChangedDuration && window.__lastMeta?.hop && Number.isFinite(Number(window.__lastMeta.hop))) {
          hop = Math.max(1, Math.round(Number(window.__lastMeta.hop)));
          effPxPerSec = sampleRate / hop;
          actualDuration = ((cropWidth - 1) * hop + fftSize) / sampleRate;
          log(`Using hop from metadata: ${hop}`);
        } else if (!userChangedDuration && (window.__lastMeta?.px_per_sec || window.__lastMeta?.pxPerSec)) {
          // Fallback to px_per_sec if hop not available and user hasn't changed duration
          const pxPerSec = Number(window.__lastMeta.px_per_sec || window.__lastMeta.pxPerSec);
          if (Number.isFinite(pxPerSec) && pxPerSec > 0) {
            hop = Math.max(1, Math.round(sampleRate / pxPerSec));
            effPxPerSec = sampleRate / hop;
            actualDuration = ((cropWidth - 1) * hop + fftSize) / sampleRate;
            log(`Using px_per_sec from metadata: ${pxPerSec.toFixed(2)} ‚Üí hop ${hop}`);
          }
        }

        // Use user's duration for hop calculation if no metadata or user changed duration
        if (!hop) {
          // duration = (cols - 1) * hop / sampleRate + fftSize / sampleRate
          // Solving for hop: hop = (duration * sampleRate - fftSize) / (cols - 1)
          let targetSamples = Math.round(durationSec * sampleRate);
          hop = Math.max(1, Math.round((targetSamples - fftSize) / Math.max(1, cropWidth - 1)));
          effPxPerSec = sampleRate / hop;
          actualDuration = ((cropWidth - 1) * hop + fftSize) / sampleRate;
          if (userChangedDuration) {
            log(`User changed duration: using ${durationSec.toFixed(3)}s ‚Üí hop ${hop}`);
          }
        }

        log(`Target duration: ${durationSec.toFixed(3)}s, Actual: ${actualDuration.toFixed(3)}s`);
        log(`${effPxPerSec.toFixed(2)} px/sec (hop ${hop})`);
        log(`fft ${fftSize}, min ${minFreq} Hz, max ${maxFreq} Hz, rows ${rows}`);
        await yieldUI();

        const imgData = ctx.getImageData(marginLeft, y0, cropWidth, rows);
        const data = imgData.data;

        // Diagnostic: Sample some pixel values to detect color space issues
        const samplePixels = [];
        for(let i = 0; i < Math.min(10, data.length/4); i++) {
          const idx = i * 4;
          samplePixels.push({r: data[idx], g: data[idx+1], b: data[idx+2], a: data[idx+3]});
        }
        console.log('[PIXEL SAMPLE] First 10 pixels:', samplePixels);

        // Check for metadata
        let hasMeta = false;
        try{
          hasMeta = !!(window.__lastMeta && (window.__lastMeta.fftSize || window.__lastMeta.hop || window.__lastMeta.pxPerSec || window.__lastMeta.px_per_sec));
        }catch(_e){ hasMeta = false; }

        let srcW = cropWidth, srcH = rows;
        let magsGrid = null;

        // For external images (no SpectroGhost metadata):
        // - If Linear scale: resample to linear FFT bins (original behavior)
        // - If Mel/Log/Bark: keep original image dimensions and let rowToBin handle the mapping
        const freqScaleValue = document.getElementById('freqScale')?.value || 'linear';
        const usePerceptualScale = (freqScaleValue === 'mel' || freqScaleValue === 'log' || freqScaleValue === 'bark');

        if(!hasMeta || window.__lastMeta?.optimized === 'false'){
          if(!usePerceptualScale) {
            // Linear scale: resample to linear FFT bins
            const sr = sampleRate;

            // Calculate hop to match target duration exactly
            const durBox = document.getElementById('assumedDurationSec');
            const desiredSec = durBox && Number(durBox.value) > 0 ? Number(durBox.value) : 1.0;
            const targetSamples = Math.round(desiredSec * sr);
            const hop = Math.max(1, Math.round((targetSamples - fftSize) / Math.max(1, srcW - 1)));

            const posBins = Math.floor(fftSize/2);
            let kMin = Math.max(0, Math.round(fftSize * (minFreq / sr)));
            let kMax = Math.min(posBins - 1, Math.round(fftSize * (maxFreq / sr)));
            if(kMax <= kMin) kMax = Math.min(posBins - 1, kMin + srcH - 1);
            const usedBins = Math.max(1, kMax - kMin + 1);

            const targetCols = 1 + Math.max(0, Math.round((targetSamples - fftSize) / Math.max(1, hop)));

            const colormapName = document.getElementById('colormapSelect')?.value || 'grayscale';
            const srgbCheckboxExt = document.getElementById('srgbGamma');
            const isLinearExt = srgbCheckboxExt ? !srgbCheckboxExt.checked : true;
            if(isLinearExt) log('Using linear pixel decoding');
            else log('Using sRGB gamma decoding');
            magsGrid = _resample2DGray(data, srcW, srcH, targetCols, usedBins, colormapName, isLinearExt);

            cropWidth = targetCols;
            rows = usedBins;
            srcW = cropWidth; srcH = rows;

            const actualDuration = ((targetCols - 1) * hop + fftSize) / sr;
            log(`Conformed external image to ${targetCols}x${usedBins} based on sr=${sr}, N=${fftSize}, hop=${hop}, target=${desiredSec.toFixed(3)}s, actual=${actualDuration.toFixed(3)}s`);
          } else {
            // Perceptual scale (Mel/Log/Bark): use original image dimensions
            // The rowToBin mapping will handle the frequency conversion
            log(`Using original image dimensions ${srcW}x${srcH} for ${freqScaleValue} scale mapping`);
          }
        }

        const cols = cropWidth;

        const mags = new Float32Array(rows*cols);
        // Flip logic: unchecked (default) means white=low/black=high (standard convention)
        // checked means black=low/white=high (legacy behavior)
        const invertFlag = !!(document.getElementById('invertColorsIn')?.checked);
        
        if(magsGrid){
          // magsGrid already holds normalized values 0..1
          for(let y=0;y<rows;y++){
            const rowOff = y*cols;
            for(let x=0;x<cols;x++){
              let t = magsGrid[y*cols + x];  // t = brightness-based position
              if(invertFlag) t = 1 - t;      // invert purely swaps bright/dark
        
              const D = Number(document.getElementById('dynRange')?.value) || 80;
              const mag = Math.pow(10, (-D * t) / 20); // correct loudness mapping
        
              mags[rowOff + x] = mag;
            }
          }
        } else {
          const colormapName = document.getElementById('colormapSelect')?.value || 'grayscale';
          log(`Using colormap: ${colormapName}`);
          const srgbCheckboxMeta = document.getElementById('srgbGamma');
          const isLinearInput = srgbCheckboxMeta ? !srgbCheckboxMeta.checked : true;
          if(isLinearInput) log('Using linear pixel decoding');
          else log('Using sRGB gamma decoding');

          for(let y=0;y<rows;y++){
            const rowOff = y*cols;
            for(let x=0;x<cols;x++){
              const idx = (y*cols + x)*4;
              const r8 = data[idx];
              const g8 = data[idx+1];
              const b8 = data[idx+2];

              // 1) Convert RGB to normalized brightness t (0=loud, 1=quiet)
              let t = rgbToColormapValue(r8, g8, b8, colormapName, isLinearInput);
        
              // 2) Apply invert purely visually
              if(invertFlag) t = 1 - t;
        
              // 3) Convert t -> linear magnitude using dynamic range
              const D = Number(document.getElementById('dynRange')?.value) || 80;
              const mag = Math.pow(10, (-D * t) / 20);
        
              mags[rowOff + x] = mag;
            }
            if(y%80===0){ log(`Row ${y}/${rows}`); await yieldUI(); }
          }
        }
        log(`Matrix complete ${rows}x${cols}`);
        if(!document.getElementById('invertColorsIn')?.checked){ log('Color interpretation: white=low, black=high (standard)'); }
        else { log('Color interpretation: black=low, white=high (inverted)'); }
        if(anyBad(mags)) warnNaNs('magnitude matrix', 'Check dynRange');
        
        if(applySmoothTime){
          log('Applied temporal smoothing (3-column avg)');
          for(let y=0;y<rows;y++){
            const rowOff=y*cols;
            let prev=mags[rowOff];
            for(let x=1;x<cols-1;x++){
              const cur=mags[rowOff+x];
              const nxt=mags[rowOff+x+1];
              mags[rowOff+x]=(prev+cur+nxt)/3;
              prev=cur;
            }
          }
        }
        
        if(applyRolloff){
          const rollBins=Math.floor(rows*0.05);
          for(let k=0;k<rows;k++){
            const f=(k>rows-rollBins)?0.5*(1-Math.cos(Math.PI*(rows-k)/rollBins)):1;
            for(let c=0;c<cols;c++){ mags[k*cols+c]*=f; }
          }
          log('Applied 5% high-end roll-off');
        }
        
        if(applyFloor){
          const minAmp = Math.pow(10, (-lowFloorDb)/20);
          let zeroed=0;
          for(let i=0;i<mags.length;i++){ if(mags[i]<minAmp){ mags[i]=0; zeroed++; } }
          log(`Applied low-level floor (-${lowFloorDb} dB), muted ${zeroed} of ${mags.length}`);
        }

        const posBins = Math.floor(fftSize/2);
        let kMin = Math.max(0, Math.round(fftSize * (minFreq / sampleRate)));
        let kMax = Math.min(posBins - 1, Math.round(fftSize * (maxFreq / sampleRate)));
        if(kMax <= kMin) kMax = Math.min(posBins - 1, kMin + rows - 1);

        // Frequency mapping: support linear, log, mel, and bark scales
        // (freqScaleValue already declared above)
        const useLog = (freqScaleValue === 'log');
        const useMel = (freqScaleValue === 'mel');
        const useBark = (freqScaleValue === 'bark');
        const flipFreq = !!(document.getElementById('flipFreqAxis')?.checked);

        // Helper to get normalized position t from row y (with optional flip)
        const getT = (y) => {
          let t = (rows - 1 - y) / Math.max(1, rows - 1);
          if(flipFreq) t = 1 - t;  // Flip: y=0 becomes low freq instead of high
          return t;
        };

        const rowToBin = new Int32Array(rows);

        // Check if user changed min/max freq from metadata values
        const metaMinHz = window.__lastMeta?.minHz;
        const metaMaxHz = window.__lastMeta?.maxHz;
        const userChangedFreqRange = (metaMinHz && Math.abs(minFreq - Number(metaMinHz)) > 0.1) ||
                                      (metaMaxHz && Math.abs(maxFreq - Number(metaMaxHz)) > 0.1);

        if(!useLog && !useMel && !useBark){
          // Linear mapping - interpolate between kMin and kMax
          // This properly handles user changes to min/max frequency
          for(let y=0;y<rows;y++){
            const t = getT(y);  // 0=low freq, 1=high freq (after flip handling)
            const k = Math.round(kMin + t * (kMax - kMin));
            rowToBin[y] = Math.max(1, Math.min(posBins - 1, k));
          }
          if(userChangedFreqRange) {
            log(`User changed freq range: mapping ${rows} rows to bins ${kMin}..${kMax}`);
          }
        } else if(useLog) {
          // Logarithmic mapping
          const minHz = Math.max(1e-3, minFreq);
          const maxHz = Math.max(minHz*1.001, maxFreq);
          for(let y=0;y<rows;y++){
            const t = getT(y);
            const f = minHz * Math.pow(maxHz/minHz, t);
            let k = Math.round((f * fftSize) / sampleRate);
            if(k < 1) k = 1;
            if(k >= posBins) k = posBins - 1;
            rowToBin[y] = k;
          }
          kMin = rowToBin.reduce((a,b)=>Math.min(a,b), posBins-1);
          kMax = rowToBin.reduce((a,b)=>Math.max(a,b), 1);
        } else if(useMel) {
          // Mel scale mapping using librosa filterbank center offsets
          // In librosa, n_mels filters have centers at Mel points 1..n_mels out of n_mels+2 total
          // This means filter centers don't reach exactly to min/max freq edges
          const minHz = Math.max(1e-3, minFreq);
          const maxHz = Math.max(minHz*1.001, maxFreq);
          const minMel = hzToMel(minHz);
          const maxMel = hzToMel(maxHz);
          const nMels = rows;
          for(let y=0;y<rows;y++){
            // Calculate which filter index this row represents
            // y=0 is top of image = highest freq filter = filter (nMels-1)
            // y=nMels-1 is bottom = lowest freq filter = filter 0
            const filterIdx = flipFreq ? y : (rows - 1 - y);
            // Filter i has its center at Mel point (i+1) out of (nMels+1) intervals
            const t = (filterIdx + 1) / (nMels + 1);
            const mel = minMel + t * (maxMel - minMel);
            const f = melToHz(mel);
            let k = Math.round((f * fftSize) / sampleRate);
            if(k < 1) k = 1;
            if(k >= posBins) k = posBins - 1;
            rowToBin[y] = k;
          }
          kMin = rowToBin.reduce((a,b)=>Math.min(a,b), posBins-1);
          kMax = rowToBin.reduce((a,b)=>Math.max(a,b), 1);
        } else if(useBark) {
          // Bark scale mapping using filterbank center offsets (same approach as Mel)
          const minHz = Math.max(1e-3, minFreq);
          const maxHz = Math.max(minHz*1.001, maxFreq);
          const minBark = hzToBark(minHz);
          const maxBark = hzToBark(maxHz);
          const nBands = rows;
          for(let y=0;y<rows;y++){
            const filterIdx = flipFreq ? y : (rows - 1 - y);
            const t = (filterIdx + 1) / (nBands + 1);
            const bark = minBark + t * (maxBark - minBark);
            const f = barkToHz(bark);
            let k = Math.round((f * fftSize) / sampleRate);
            if(k < 1) k = 1;
            if(k >= posBins) k = posBins - 1;
            rowToBin[y] = k;
          }
          kMin = rowToBin.reduce((a,b)=>Math.min(a,b), posBins-1);
          kMax = rowToBin.reduce((a,b)=>Math.max(a,b), 1);
        }

        // Log diagnostic info for frequency mapping
        if(useLog || useMel || useBark) {
          const topFreq = (rowToBin[0] * sampleRate) / fftSize;
          const midFreq = (rowToBin[Math.floor(rows/2)] * sampleRate) / fftSize;
          const botFreq = (rowToBin[rows-1] * sampleRate) / fftSize;
          log(`Freq mapping (${freqScaleValue}${flipFreq?' flipped':''}): top=${topFreq.toFixed(0)}Hz, mid=${midFreq.toFixed(0)}Hz, bot=${botFreq.toFixed(0)}Hz`);
        }

        const usedSet = new Set();
        for(let y=0;y<rows;y++) usedSet.add(rowToBin[y]);
        const binList = Array.from(usedSet).sort((a,b)=>a-b);
        const binToIdx = Object.create(null);
        for(let i=0;i<binList.length;i++) binToIdx[binList[i]] = i;
        const usedBins = binList.length;
        const effMinHz = (kMin * sampleRate) / fftSize;
        const effMaxHz = (kMax * sampleRate) / fftSize;
        log(`${freqScaleValue.charAt(0).toUpperCase() + freqScaleValue.slice(1)} freq map ${effMinHz.toFixed(1)}..${effMaxHz.toFixed(1)} Hz across ${rows} rows -> ${usedBins} unique bins`);
        log(`Bins k ${kMin}..${kMax} (used ${usedBins}), binHz ${(sampleRate/fftSize).toFixed(2)}`);

        let magsWork = mags;
        if(reverse){
          magsWork = new Float32Array(rows*cols);
          for(let y=0;y<rows;y++){
            const rowOff = y*cols;
            for(let x=0;x<cols;x++){
              magsWork[rowOff + x] = mags[rowOff + (cols - 1 - x)];
            }
          }
          log('Time reversal: columns flipped for GL/PGHI');
        }

        // Frame interpolation to increase overlap (reduce wobble)
        const shouldInterpolate = document.getElementById('interpolateFrames')?.checked;
        let workCols = cols;
        let workHop = hop;

        if (shouldInterpolate) {
          const currentOverlap = ((fftSize - hop) / fftSize) * 100;
          const targetOverlapPct = Number(document.getElementById('targetOverlap')?.value) || 75;

          if (targetOverlapPct > currentOverlap + 1) {
            // Calculate new hop for target overlap
            const newHop = Math.round(fftSize * (1 - targetOverlapPct / 100));
            const interpFactor = hop / newHop;
            const newCols = Math.round(cols * interpFactor);

            log(`Interpolating frames: ${cols} ‚Üí ${newCols} (overlap ${currentOverlap.toFixed(1)}% ‚Üí ${targetOverlapPct}%, hop ${hop} ‚Üí ${newHop})`);

            // Interpolate magnitude spectrogram
            const interpMags = new Float32Array(rows * newCols);
            for (let y = 0; y < rows; y++) {
              for (let x = 0; x < newCols; x++) {
                const srcX = (x / newCols) * cols;
                const x0 = Math.floor(srcX);
                const x1 = Math.min(x0 + 1, cols - 1);
                const frac = srcX - x0;

                const v0 = magsWork[y * cols + x0];
                const v1 = magsWork[y * cols + x1];
                interpMags[y * newCols + x] = v0 * (1 - frac) + v1 * frac;
              }
            }

            magsWork = interpMags;
            workCols = newCols;
            workHop = newHop;
          } else {
            log(`Skipping interpolation: current overlap ${currentOverlap.toFixed(1)}% >= target ${targetOverlapPct}%`);
          }
        }

        // Temporal magnitude smoothing to reduce warble from quantization noise
        // Smooth each row (frequency bin) across time with a 3-frame moving average
        const smoothMags = document.getElementById('smoothMagnitude')?.checked;
        if(smoothMags){
          log('Applying temporal magnitude smoothing...');
          const smoothed = new Float32Array(rows * workCols);
          for(let y=0; y<rows; y++){
            const rowOff = y * workCols;
            for(let x=0; x<workCols; x++){
              // 3-frame weighted average: [0.25, 0.5, 0.25]
              const x0 = Math.max(0, x-1);
              const x1 = x;
              const x2 = Math.min(workCols-1, x+1);
              smoothed[rowOff + x] = 0.25 * magsWork[rowOff + x0] +
                                     0.5 * magsWork[rowOff + x1] +
                                     0.25 * magsWork[rowOff + x2];
            }
          }
          magsWork = smoothed;
          log('Magnitude smoothing complete');
        }

        if(phaseMethod === 'istft'){
          log('Zero Phase synthesis');
          log(`Zero Phase: rows=${rows}, kMin=${kMin}, kMax=${kMax}, hop=${workHop}, fft=${fftSize}`);
          let istftSignal = await istftReconstruct(magsWork, rows, workCols, sampleRate, fftSize, workHop, kMin, kMax, rowToBin, log);
          await finalizeAudio(istftSignal, sampleRate, effPxPerSec);
          return;
        } else if(phaseMethod === 'griffinlim'){
          log(`Fast Griffin-Lim (FGLA) x ${iterations}`);
          if(iterations < 8) log('Tip: Griffin-Lim usually needs 12-32 iterations for clear speech.');
          log(`GL using rows=${rows}, kMin=${kMin}, kMax=${kMax}, hop=${workHop}, fft=${fftSize}`);
          let glSignal = await griffinLimReconstruct(magsWork, rows, workCols, sampleRate, fftSize, workHop, kMin, kMax, rowToBin, iterations, log);
          await finalizeAudio(glSignal, sampleRate, effPxPerSec);
          return;
        } else if(phaseMethod === 'pghi_true'){
          log(`PGHI reconstruction`);
          let pghiTrueSignal = await truePghiReconstruct(magsWork, rows, workCols, sampleRate, fftSize, workHop, kMin, kMax, rowToBin, iterations, log);
          await finalizeAudio(pghiTrueSignal, sampleRate, effPxPerSec);
          return;
        } else if(phaseMethod === 'neural'){
          log('Neural Vocoder reconstruction');
          try {
            let neuralSignal = await neuralVocoderReconstruct(magsWork, rows, workCols, sampleRate, fftSize, workHop, kMin, kMax, rowToBin, log);
            await finalizeAudio(neuralSignal, sampleRate, effPxPerSec);
          } catch (err) {
            log(`Neural vocoder error: ${err.message}`);
            log('Please load a vocoder model first using the "Load Model" button.');
          }
          return;
        } else if(phaseMethod === 'running'){
          log('Additive Synthesis');
          const outLen = workHop*(workCols - 1) + fftSize;
          const signal = new Float32Array(outLen);
          const w = (workHop < fftSize) ? hannWindow(fftSize) : null;
          const phases = new Float32Array(usedBins);
          // Normalize for overlap-add: each sample receives contributions from (fftSize/hop) frames
          // Factor of 6 empirically tuned to match Griffin-Lim output levels
          const overlapNorm = workHop / fftSize / 6;
          const gainNorm = preGain * overlapNorm;
          // Precompute phase increments per bin (2œÄ * freq / sampleRate)
          const phaseIncs = new Float32Array(usedBins);
          const hopPhaseIncs = new Float32Array(usedBins);
          for(let y=0; y<rows; y++){
            const k = rowToBin[y];
            const bin = binToIdx[k];
            if(bin >= 0 && bin < usedBins){
              const freq = (k * sampleRate) / fftSize;
              phaseIncs[bin] = 2 * Math.PI * freq / sampleRate;
              hopPhaseIncs[bin] = phaseIncs[bin] * workHop;
            }
          }
          for(let b=0;b<usedBins;b++) phases[b]=0;
          const signalLen = signal.length;
          for(let c=0;c<workCols;c++){
            const src = reverse ? (workCols - 1 - c) : c;
            const start = c * workHop;
            const maxT = Math.min(fftSize, signalLen - start);
            for(let y=0;y<rows;y++){
              const k = rowToBin[y];
              const bin = binToIdx[k];
              const a = magsWork[y*workCols + src] * gainNorm;
              if(a<=0) continue;
              const phaseInc = phaseIncs[bin];
              let ph = phases[bin];
              if(w){
                for(let t=0; t<maxT; t++){
                  signal[start + t] += a * Math.sin(ph) * w[t];
                  ph += phaseInc;
                }
              } else {
                for(let t=0; t<maxT; t++){
                  signal[start + t] += a * Math.sin(ph);
                  ph += phaseInc;
                }
              }
              phases[bin] += hopPhaseIncs[bin];
              // Keep phase in reasonable range to avoid precision loss
              if(phases[bin] > 6.283185) phases[bin] -= 6.283185307179586;
            }
            if(c%100===0){ log(`Col ${c}/${workCols}`); await yieldUI(); }
          }
          await finalizeAudio(signal, sampleRate, effPxPerSec);
        }
      };
      
      // If we have a file, load it. Otherwise, canvas already has pasted image
      if(file){
        const img = new Image();
        const url = URL.createObjectURL(file);
        img.onload = async ()=>{
          canvas.width = img.width;
          canvas.height = img.height;
          ctx.imageSmoothingEnabled = false;
          ctx.drawImage(img, 0, 0);
          URL.revokeObjectURL(url);
          await processCanvasContent();
        };
        img.onerror = ()=> {
          URL.revokeObjectURL(url);
          setStatus('Failed to load image');
        };
        img.src = url;
      } else {
        // Canvas already has the pasted image, process it directly
        await processCanvasContent();
      }
    }

    async function finalizeAudio(signal, sampleRate, pxPerSec){
      const pgEl = document.getElementById('postGainSlider');
      const postGain = pgEl ? parseFloat(pgEl.value) : 1.0;
      if(postGain !== 1){ for(let i=0;i<signal.length;i++){ signal[i] *= postGain; } }

      for(let i=0;i<signal.length;i++){ if(!Number.isFinite(signal[i]) || Number.isNaN(signal[i])) signal[i]=0; }

      // Apply short fade-in/fade-out to prevent click/chirp artifacts
      const fadeMs = 5;
      const fadeSamples = Math.min(Math.round(sampleRate * fadeMs / 1000), Math.floor(signal.length / 2));
      // Fade-in at start
      for(let i = 0; i < fadeSamples; i++){
        const t = i / fadeSamples; // 0 at start, approaches 1 at fade end
        const env = 0.5 * (1 - Math.cos(Math.PI * t)); // Cosine fade: 0 at start, 1 at fade end
        signal[i] *= env;
      }
      // Fade-out at end
      for(let i = 0; i < fadeSamples; i++){
        const t = i / fadeSamples; // 0 at end, approaches 1 at fade start
        const env = 0.5 * (1 - Math.cos(Math.PI * t)); // Cosine fade: 0 at end, 1 at fade start
        signal[signal.length - 1 - i] *= env;
      }

      log('Encoding WAV');
      await yieldUI();
      const wav = encodeWAV(signal, sampleRate);
      const blob = new Blob([wav], {type:'audio/wav'});
      const url = URL.createObjectURL(blob);
      const a = document.getElementById('audioPlayer');
      a.src = url;
      a.play().catch(()=>{});
      const d = document.getElementById('downloadBtn');
      d.dataset.url = url;
      d.style.display = 'inline-block';
      log('Audio ready. Use the player or Download.');

      // Initialize playhead
      audioElement = a;
      audioDuration = signal.length / sampleRate;
      pixelsPerSecond = pxPerSec; // Use the px/sec passed from reconstruction

      console.log(`[PLAYHEAD] Initializing...`);
      console.log(`[PLAYHEAD]   audioElement:`, audioElement);
      console.log(`[PLAYHEAD]   duration: ${audioDuration.toFixed(2)}s`);
      console.log(`[PLAYHEAD]   px/sec: ${pixelsPerSecond.toFixed(2)}`);
      console.log(`[PLAYHEAD]   canvas.width: ${canvas.width}`);

      // Attach playhead update listener
      a.removeEventListener('timeupdate', onAudioTimeUpdate); // Remove old listener if any
      a.addEventListener('timeupdate', onAudioTimeUpdate);

      // Reset playhead to start
      updatePlayheadPosition(0);

      console.log(`[PLAYHEAD] Initialized successfully`);
    }

    function encodeWAV(samples, sampleRate){
      const numChannels=1, bps=2, blockAlign=numChannels*bps, byteRate=sampleRate*blockAlign;
      const dataSize=samples.length*bps;
      const buf=new ArrayBuffer(44+dataSize);
      const v=new DataView(buf);
      function ws(o,s){ for(let i=0;i<s.length;i++) v.setUint8(o+i, s.charCodeAt(i)); }
      ws(0,"RIFF"); v.setUint32(4,36+dataSize,true);
      ws(8,"WAVE"); ws(12,"fmt "); v.setUint32(16,16,true);
      v.setUint16(20,1,true); v.setUint16(22,1,true);
      v.setUint32(24,sampleRate,true); v.setUint32(28,byteRate,true);
      v.setUint16(32,blockAlign,true); v.setUint16(34,16,true);
      ws(36,"data"); v.setUint32(40,dataSize,true);
      let off=44;
      for(let i=0;i<samples.length;i++){
        const s=Math.max(-1,Math.min(1,samples[i]));
        v.setInt16(off, s*32767, true);
        off+=2;
      }
      return buf;
    }

    // Cache Hann windows by size - avoids recomputing N cos() calls on every stft/istft
    const _hannCache = new Map();
    function hannWindow(n){
      if(_hannCache.has(n)) return _hannCache.get(n);
      const w=new Float32Array(n);
      for(let i=0;i<n;i++) w[i]=0.5*(1-Math.cos(2*Math.PI*i/(n-1)));
      _hannCache.set(n, w);
      return w;
    }

    // Cache FFT twiddle factors by size - avoids recomputing cos/sin on every FFT call
    const _twiddleCache = new Map();
    function getTwiddles(n){
      if(_twiddleCache.has(n)) return _twiddleCache.get(n);
      const twiddles = [];
      for(let len=2; len<=n; len<<=1){
        const half = len >> 1;
        const cos = new Float32Array(half);
        const sin = new Float32Array(half);
        for(let k=0; k<half; k++){
          const ang = -2 * Math.PI * k / len;
          cos[k] = Math.cos(ang);
          sin[k] = Math.sin(ang);
        }
        twiddles.push({cos, sin});
      }
      _twiddleCache.set(n, twiddles);
      return twiddles;
    }

    // Cache squared Hann windows for istft normalization - avoids w[i]*w[i] on every frame
    const _hannSqCache = new Map();
    function hannWindowSq(n){
      if(_hannSqCache.has(n)) return _hannSqCache.get(n);
      const w = hannWindow(n);
      const wsq = new Float32Array(n);
      for(let i=0; i<n; i++) wsq[i] = w[i] * w[i];
      _hannSqCache.set(n, wsq);
      return wsq;
    }

    /**
    * Convert Hz to Mel scale (HTK formula)
    * @param {number} hz - Frequency in Hz
    * @returns {number} Mel value
    */
    function hzToMelHTK(hz) {
     return 2595 * Math.log10(1 + hz / 700);
    }

    /**
    * Convert Mel to Hz (HTK formula)
    * @param {number} mel - Mel value
    * @returns {number} Frequency in Hz
    */
    function melToHzHTK(mel) {
     return 700 * (Math.pow(10, mel / 2595) - 1);
    }

    /**
    * Convert Hz to Mel scale (Slaney/Librosa formula)
    * Used by librosa, NVIDIA DALI, and many ML frameworks
    */
    function hzToMelSlaney(hz) {
      const f_sp = 200.0 / 3.0;  // ~66.67 Hz
      const min_log_hz = 1000.0;
      const min_log_mel = min_log_hz / f_sp;  // 15.0
      const logstep = Math.log(6.4) / 27.0;

      if (hz < min_log_hz) {
        return hz / f_sp;
      } else {
        return min_log_mel + Math.log(hz / min_log_hz) / logstep;
      }
    }

    /**
    * Convert Mel to Hz (Slaney/Librosa formula)
    */
    function melToHzSlaney(mel) {
      const f_sp = 200.0 / 3.0;
      const min_log_hz = 1000.0;
      const min_log_mel = min_log_hz / f_sp;  // 15.0
      const logstep = Math.log(6.4) / 27.0;

      if (mel < min_log_mel) {
        return mel * f_sp;
      } else {
        return min_log_hz * Math.exp((mel - min_log_mel) * logstep);
      }
    }

    // Wrapper functions that use the selected Mel formula
    function hzToMel(hz) {
      const melType = document.getElementById('melType')?.value || 'htk';
      return melType === 'slaney' ? hzToMelSlaney(hz) : hzToMelHTK(hz);
    }

    function melToHz(mel) {
      const melType = document.getElementById('melType')?.value || 'htk';
      return melType === 'slaney' ? melToHzSlaney(mel) : melToHzHTK(mel);
    }
    
    /**
    * Convert Hz to Bark scale
    * @param {number} hz - Frequency in Hz
    * @returns {number} Bark value
    */
    function hzToBark(hz) {
     return 13 * Math.atan(0.00076 * hz) + 3.5 * Math.atan(Math.pow(hz / 7500, 2));
    }
    
    /**
    * Convert Bark to Hz (approximation)
    * @param {number} bark - Bark value
    * @returns {number} Frequency in Hz
    */
    function barkToHz(bark) {
     // Approximation formula
     return 600 * Math.sinh(bark / 6);
    }
    
    function fftRadix2(re, im, inverse=false){
      const n=re.length;
      // Bit-reversal permutation
      for(let i=1,j=0;i<n;i++){
        let bit=n>>1;
        for(; j & bit; bit>>=1) j^=bit;
        j^=bit;
        if(i<j){ let tr=re[i]; re[i]=re[j]; re[j]=tr; tr=im[i]; im[i]=im[j]; im[j]=tr; }
      }
      // Use cached twiddle factors instead of computing cos/sin each time
      const twiddles = getTwiddles(n);
      const sign = inverse ? -1 : 1;
      let stage = 0;
      for(let len=2; len<=n; len<<=1){
        const {cos, sin} = twiddles[stage++];
        const half = len >> 1;
        for(let i=0; i<n; i+=len){
          for(let k=0; k<half; k++){
            const j=i+k, l=j+half;
            const wr = cos[k], wi = sign * sin[k];
            const tr = wr*re[l] - wi*im[l];
            const ti = wr*im[l] + wi*re[l];
            re[l]=re[j]-tr; im[l]=im[j]-ti;
            re[j]+=tr; im[j]+=ti;
          }
        }
      }
      if(inverse){ const inv=1/n; for(let i=0;i<n;i++){ re[i]*=inv; im[i]*=inv; } }
    }

    function stft(signal, fftSize, hop){
      const w = hannWindow(fftSize);
      const frames = Math.max(1, Math.floor((signal.length - fftSize)/hop) + 1);
      const spec = new Array(frames);
      for(let f=0; f<frames; f++){
        const start = f*hop;
        const re = new Float32Array(fftSize);
        const im = new Float32Array(fftSize);
        for(let i=0;i<fftSize;i++){ re[i] = (signal[start+i]||0)*w[i]; im[i]=0; }
        fftRadix2(re, im, false);
        spec[f] = {re, im};
      }
      return {spec, fftSize, hop};
    }

    function istft(specObj, hop, outLen){
      const {spec, fftSize} = specObj;
      const w = hannWindow(fftSize);
      const wsq = hannWindowSq(fftSize);  // Pre-computed w[i]*w[i]
      const out = new Float32Array(outLen);
      const norm = new Float32Array(outLen);
      for(let f=0; f<spec.length; f++){
        const re=spec[f].re.slice(), im=spec[f].im.slice();
        fftRadix2(re, im, true);
        const start = f*hop;
        for(let i=0;i<fftSize;i++){
          const s = re[i] * w[i]; // Apply synthesis window
          out[start+i]+=s;
          norm[start+i]+=wsq[i];  // Use cached squared window
        }
      }
      for(let i=0;i<out.length;i++){ const d = norm[i]; out[i] = (d>1e-12)? (out[i]/d) : 0; }
      if(anyBad(out)) warnNaNs('iSTFT output', 'NaN or Inf after overlap add');
      return out;
    }

    async function pghiLikeReconstruct(magRowsCols, rows, cols, fs, N, hop, kMin, kMax, rowToBin, iters, logFn){
      const preGain = __getPreGain();
      const posBins = Math.floor(N/2);
      const frames = cols;
      const target = new Array(frames);
      for(let c=0;c<frames;c++){
        const mag = new Float32Array(posBins);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k>=0 && k<posBins){
            const a = magRowsCols[y*cols + c];
            if(a>mag[k]) mag[k]=a;
          }
        }
        const specScale = N / 2;
        for(let k=0;k<posBins;k++){ mag[k] *= specScale; mag[k] *= preGain; }
        target[c]=mag;
      }

      const spec = new Array(frames);
      const phases = new Float32Array(posBins);
      for(let k=0;k<posBins;k++) phases[k]=0;
      const binHz = fs / N;
      const dt = hop / fs;

      for(let c=0;c<frames;c++){
        const re = new Float32Array(N);
        const im = new Float32Array(N);
        for(let k=0;k<posBins;k++){
          const a = target[c][k];
          const freq = k * binHz;
          const ph = phases[k];
          re[k] = a * Math.cos(ph);
          im[k] = a * Math.sin(ph);
          let phNext = phases[k] + 2*Math.PI*freq*dt;
          if(phNext > Math.PI) phNext -= 2*Math.PI;
          if(phNext < -Math.PI) phNext += 2*Math.PI;
          phases[k] = phNext;
        }
        im[0]=0; const ny = posBins; re[ny]=0; im[ny]=0;
        for(let k=1;k<posBins;k++){ re[N-k]=re[k]; im[N-k] = -im[k]; }
        spec[c] = {re, im};
      }

      const outLen = hop*(frames - 1) + N;
      let signal = istft({spec, fftSize: N}, hop, outLen);
      logFn && logFn("Applied PGHI phase unwrapping for continuity\nPGHI-like: coherent init done");

      const refine = Math.max(0, iters|0);
      for(let it=0; it<refine; it++){
        if(anyBad(signal)) warnNaNs('PGHI-like refine '+(it+1), 'Signal contains invalid numbers');
        const ana = stft(signal, N, hop);
        for(let c=0;c<frames;c++){
          const re=ana.spec[c].re, im=ana.spec[c].im;
          for(let k=0;k<posBins;k++){
            let ph = Math.atan2(im[k], re[k]);
            const expected = (phases[k] + 2*Math.PI*(k*fs/N)*dt) % (2*Math.PI);
            let diff = ph - expected;
            if(diff > Math.PI) diff -= 2*Math.PI;
            if(diff < -Math.PI) diff += 2*Math.PI;
            ph = expected + diff;
            phases[k] = ph;
            const a = target[c][k];
            re[k] = a*Math.cos(ph);
            im[k] = a*Math.sin(ph);
          }
          for(let k=1;k<posBins;k++){ ana.spec[c].re[N-k]=ana.spec[c].re[k]; ana.spec[c].im[N-k]=-ana.spec[c].im[k]; }
          ana.spec[c].im[0]=0; ana.spec[c].re[posBins]=0; ana.spec[c].im[posBins]=0;
        }
        signal = istft({spec: ana.spec, fftSize: N}, hop, outLen);
        if(it%2===0){ logFn && logFn(`PGHI-like refine ${it+1}/${refine}`); await new Promise(r=>requestAnimationFrame(r)); }
      }
      return signal;
    }

    // Binary max-heap for O(log n) push/pop - replaces O(n log n) array.sort() in PGHI
    class MaxHeap {
      constructor() { this.d = []; }
      get length() { return this.d.length; }
      push(priority, value) {
        this.d.push([priority, value]);
        let i = this.d.length - 1;
        while (i > 0) {
          const p = (i - 1) >> 1;
          if (this.d[p][0] >= this.d[i][0]) break;
          [this.d[p], this.d[i]] = [this.d[i], this.d[p]];
          i = p;
        }
      }
      pop() {
        if (this.d.length === 0) return null;
        const top = this.d[0];
        const last = this.d.pop();
        if (this.d.length > 0) {
          this.d[0] = last;
          let i = 0;
          while (true) {
            const l = (i << 1) + 1, r = l + 1;
            let largest = i;
            if (l < this.d.length && this.d[l][0] > this.d[largest][0]) largest = l;
            if (r < this.d.length && this.d[r][0] > this.d[largest][0]) largest = r;
            if (largest === i) break;
            [this.d[i], this.d[largest]] = [this.d[largest], this.d[i]];
            i = largest;
          }
        }
        return top;
      }
    }

    async function truePghiReconstruct(magsWork, rows, cols, fs, N, hop, kMin, kMax, rowToBin, iters, logFn){
      const preGain = __getPreGain();
      const posBins = Math.floor(N/2);
      const frames = cols;

      const target = new Array(frames);
      for(let c=0;c<frames;c++){
        let maxA = 0;
        const mag = new Float32Array(posBins);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k>=0 && k<posBins){
            const a = magsWork[y*cols + c];
            if(a>mag[k]) mag[k]=a;
            if(a>maxA) maxA=a;
          }
        }
        // Apply noise floor (matching Griffin-Lim)
        const floorA = maxA * 1e-4;
        for(let k=0;k<posBins;k++){ if(mag[k] < floorA) mag[k] = 0; }
        const specScale = N / 2;
        for(let k=0;k<posBins;k++){ mag[k] *= specScale; mag[k] *= preGain; }
        target[c]=mag;
      }

      logFn("PGHI: computing phase gradients...");
      await new Promise(r=>requestAnimationFrame(r));

      const logMag = new Float32Array(rows*cols);
      for(let i=0;i<magsWork.length;i++) logMag[i] = Math.log(magsWork[i] + 1e-9);

      const dT = new Float32Array(rows*cols);
      const dF = new Float32Array(rows*cols);
      for(let y=0;y<rows;y++){
        for(let x=1;x<cols-1;x++){
          const idx = y*cols + x;
          dT[idx] = (logMag[y*cols + x+1] - logMag[y*cols + x-1]) * 0.5;
        }
      }
      for(let x=0;x<cols;x++){
        for(let y=1;y<rows-1;y++){
          const idx = y*cols + x;
          dF[idx] = (logMag[(y+1)*cols + x] - logMag[(y-1)*cols + x]) * 0.5;
        }
      }

      const dPhiT = new Float32Array(rows*cols);
      const dPhiF = new Float32Array(rows*cols);
      const twoPi = 2 * Math.PI;
      // PGHI for Hann window: gamma ‚âà (N * hop) / (8 * ln(2)) for time-frequency product
      // For time direction: correction = gamma * (discrete freq gradient)
      // For freq direction: correction = (1/gamma) * (discrete time gradient)
      // Discrete gradients are already normalized by the difference spacing
      const gamma = (N * hop) / (8 * Math.log(2));  // Hann window approximation
      const scaleT = gamma / (N * N);  // Scale for freq gradient -> time phase
      const scaleF = 1 / gamma;        // Scale for time gradient -> freq phase
      for(let y = 0; y < rows; y++){
        for(let x = 0; x < cols; x++){
          const idx = y * cols + x;
          dPhiT[idx] = scaleT * dF[idx];
          dPhiF[idx] = scaleF * dT[idx];
        }
      }

      logFn("Heap integration in progress...");
      await new Promise(r=>requestAnimationFrame(r));

      const phase = new Float32Array(rows*cols).fill(NaN);
      const visited = new Uint8Array(rows*cols);

      // Use binary max-heap instead of array + sort() - O(log n) vs O(n log n) per operation
      const heap = new MaxHeap();

      // Find the highest-magnitude pixel to seed
      let seedIdx = 0, maxMag = 0;
      for(let i=0; i<magsWork.length; i++){
        if(magsWork[i] > maxMag){ maxMag = magsWork[i]; seedIdx = i; }
      }
      if(maxMag === 0){
        logFn("PGHI: empty magnitude matrix.");
        return new Float32Array();
      }

      // Seed the highest-magnitude pixel with phase 0 and add to heap
      phase[seedIdx] = 0;
      visited[seedIdx] = 1;
      heap.push(magsWork[seedIdx], seedIdx);

      while(heap.length > 0){
        const entry = heap.pop();
        if(!entry) break;
        const [magVal, idx] = entry;
        const y = Math.floor(idx / cols);
        const x = idx - y * cols;

        // Get the frequency bin for this row to compute carrier term
        const k = rowToBin[y];
        // Carrier phase advance per hop in time: 2œÄ * k * hop / N
        const carrier = twoPi * k * hop / N;

        // Process unvisited neighbors - assign phase, mark visited, add to heap
        // Time direction: phase advances by carrier + PGHI correction
        // Right (dx=+1)
        if(x + 1 < cols && !visited[idx + 1]){
          phase[idx + 1] = phase[idx] + carrier + dPhiT[idx];
          visited[idx + 1] = 1;
          heap.push(magsWork[idx + 1], idx + 1);
        }
        // Left (dx=-1)
        if(x > 0 && !visited[idx - 1]){
          phase[idx - 1] = phase[idx] - carrier - dPhiT[idx];
          visited[idx - 1] = 1;
          heap.push(magsWork[idx - 1], idx - 1);
        }
        // Down (dy=+1) - frequency direction, no carrier term
        if(y + 1 < rows && !visited[idx + cols]){
          phase[idx + cols] = phase[idx] + dPhiF[idx];
          visited[idx + cols] = 1;
          heap.push(magsWork[idx + cols], idx + cols);
        }
        // Up (dy=-1) - frequency direction, no carrier term
        if(y > 0 && !visited[idx - cols]){
          phase[idx - cols] = phase[idx] - dPhiF[idx];
          visited[idx - cols] = 1;
          heap.push(magsWork[idx - cols], idx - cols);
        }
      }

      let visitCount = 0;
      for(let i=0; i<rows*cols; i++) if(visited[i]) visitCount++;
      logFn(`Heap integration complete (${visitCount} bins)`);

      const spec = new Array(frames);
      for(let c=0;c<frames;c++){
        const re = new Float32Array(N);
        const im = new Float32Array(N);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k<=0 || k>=posBins) continue;
          const idx = y*cols + c;
          const a = target[c][k];
          const ph = phase[idx];
          if(a > 0){
            re[k] = a*Math.cos(ph);
            im[k] = a*Math.sin(ph);
          }
        }
        im[0]=0; re[posBins]=0; im[posBins]=0;
        for(let k=1;k<posBins;k++){ re[N-k]=re[k]; im[N-k]=-im[k]; }
        spec[c] = {re, im};
      }

      logFn("ISTFT synthesis...");
      const outLen = hop*(frames - 1) + N;
      const signal = istft({spec, fftSize:N}, hop, outLen);
      // PGHI produces lower energy than Griffin-Lim due to phase spreading
      // Boost by ~8.5 dB (factor of 2.7) to match FGLA output levels
      const pghiGainBoost = 2.7;
      for(let i = 0; i < signal.length; i++) signal[i] *= pghiGainBoost;
      logFn("ISTFT synthesis done.");
      return signal;
    }

    // ============================================
    // NEURAL VOCODER FUNCTIONS
    // ============================================
    //
    // Neural vocoders provide much better audio quality than Griffin-Lim.
    // This implementation uses ONNX Runtime Web to run pre-trained models.
    //
    // HOW TO USE:
    // 1. Get an ONNX vocoder model (MelGAN, HiFi-GAN, or similar)
    // 2. Host it somewhere accessible (GitHub, CDN, local server)
    // 3. Select "Neural Vocoder" from the Phase Reconstruction method
    // 4. Enter the model URL and click "Load Model"
    // 5. Run the reconstruction
    //
    // WHERE TO GET MODELS:
    // - HuggingFace Model Hub (many MIT/Apache2 licensed models)
    // - ONNX Model Zoo: https://github.com/onnx/models
    // - Convert PyTorch models to ONNX yourself
    //
    // EXAMPLE MODELS (check licenses before use):
    // - LJSpeech MelGAN: ~10MB, good quality
    // - Universal MelGAN: works with various speakers
    // - HiFi-GAN V1: excellent quality, larger size
    //
    // LICENSE COMPATIBILITY:
    // This code is MIT licensed. Ensure any model you use has a compatible
    // license (MIT, Apache 2.0, BSD, etc.). Many models on HuggingFace are
    // MIT or Apache 2.0 licensed.
    //
    // ============================================

    let __vocoderSession = null;
    let __vocoderModelLoaded = false;

    /**
     * Load ONNX vocoder model
     */
    async function loadVocoderModel(modelUrl, logFn) {
      try {
        logFn && logFn(`Loading vocoder model from: ${modelUrl}`);
        __vocoderSession = await ort.InferenceSession.create(modelUrl);
        __vocoderModelLoaded = true;
        logFn && logFn(`Vocoder model loaded successfully`);
        return true;
      } catch (err) {
        logFn && logFn(`Error loading vocoder: ${err.message}`);
        __vocoderModelLoaded = false;
        return false;
      }
    }

    /**
     * Convert linear spectrogram to mel-spectrogram
     * @param {Float32Array} linearSpec - Linear magnitude spectrogram [frames, bins]
     * @param {number} frames - Number of time frames
     * @param {number} linearBins - Number of linear frequency bins
     * @param {number} sampleRate - Sample rate in Hz
     * @param {number} nMels - Number of mel bins (default 80)
     * @param {number} fMin - Minimum frequency in Hz
     * @param {number} fMax - Maximum frequency in Hz
     * @returns {Float32Array} Mel-spectrogram [frames, nMels]
     */
    function linearToMelSpectrogram(linearSpec, frames, linearBins, sampleRate, nMels = 80, fMin = 0, fMax = null) {
      if (!fMax) fMax = sampleRate / 2;

      // Create mel filterbank
      const melMin = hzToMel(fMin);
      const melMax = hzToMel(fMax);
      const melPoints = new Float32Array(nMels + 2);
      for (let i = 0; i < nMels + 2; i++) {
        melPoints[i] = melToHz(melMin + (i / (nMels + 1)) * (melMax - melMin));
      }

      // Convert mel points to FFT bin numbers
      const binPoints = new Float32Array(nMels + 2);
      for (let i = 0; i < nMels + 2; i++) {
        binPoints[i] = Math.floor((linearBins + 1) * melPoints[i] / (sampleRate / 2));
      }

      // Create mel filterbank matrix
      const melFilters = [];
      for (let m = 0; m < nMels; m++) {
        const filter = new Float32Array(linearBins);
        const leftBin = binPoints[m];
        const centerBin = binPoints[m + 1];
        const rightBin = binPoints[m + 2];

        // Triangular filter
        for (let k = 0; k < linearBins; k++) {
          if (k >= leftBin && k <= centerBin && centerBin > leftBin) {
            filter[k] = (k - leftBin) / (centerBin - leftBin);
          } else if (k > centerBin && k <= rightBin && rightBin > centerBin) {
            filter[k] = (rightBin - k) / (rightBin - centerBin);
          }
        }
        melFilters.push(filter);
      }

      // Apply mel filterbank to linear spectrogram
      const melSpec = new Float32Array(frames * nMels);
      for (let t = 0; t < frames; t++) {
        for (let m = 0; m < nMels; m++) {
          let sum = 0;
          for (let k = 0; k < linearBins; k++) {
            sum += linearSpec[t * linearBins + k] * melFilters[m][k];
          }
          melSpec[t * nMels + m] = sum;
        }
      }

      return melSpec;
    }

    /**
     * Simple linear resampling
     */
    function resampleAudio(input, inputRate, outputRate) {
      if (inputRate === outputRate) return input;
      const ratio = outputRate / inputRate;
      const outputLength = Math.floor(input.length * ratio);
      const output = new Float32Array(outputLength);

      for (let i = 0; i < outputLength; i++) {
        const srcPos = i / ratio;
        const srcIdx = Math.floor(srcPos);
        const frac = srcPos - srcIdx;

        if (srcIdx + 1 < input.length) {
          output[i] = input[srcIdx] * (1 - frac) + input[srcIdx + 1] * frac;
        } else {
          output[i] = input[srcIdx];
        }
      }

      return output;
    }

    /**
     * Neural vocoder reconstruction
     */
    async function neuralVocoderReconstruct(magRowsCols, rows, cols, fs, N, hop, kMin, kMax, rowToBin, logFn) {
      if (!__vocoderModelLoaded || !__vocoderSession) {
        logFn && logFn('ERROR: Vocoder model not loaded. Please load a model first.');
        throw new Error('Vocoder model not loaded');
      }

      const preGain = __getPreGain();
      const posBins = Math.floor(N / 2);
      const frames = cols;

      // Get model sample rate from UI
      const modelSampleRateEl = document.getElementById('vocoderSampleRate');
      const modelSampleRate = modelSampleRateEl ? Number(modelSampleRateEl.value) : 22050;

      logFn && logFn(`Neural vocoder: frames=${frames}, bins=${posBins}, input_sr=${fs}, model_sr=${modelSampleRate}`);

      // Build linear magnitude spectrogram
      const linearSpec = new Float32Array(frames * posBins);
      for (let c = 0; c < frames; c++) {
        for (let y = 0; y < rows; y++) {
          const k = rowToBin[y];
          if (k >= 0 && k < posBins) {
            const a = magRowsCols[y * cols + c] * preGain;
            linearSpec[c * posBins + k] = a;
          }
        }
      }

      // Convert to mel-spectrogram (80 mel bins is standard for vocoders)
      // IMPORTANT: Limit to model's Nyquist frequency to avoid bandwidth mismatch
      const modelNyquist = modelSampleRate / 2;
      const effectiveMaxFreq = Math.min(fs / 2, modelNyquist);
      logFn && logFn(`Converting to mel-spectrogram (0-${effectiveMaxFreq.toFixed(0)}Hz, clamped to model Nyquist)...`);
      const nMels = 80;
      let melSpec = linearToMelSpectrogram(linearSpec, frames, posBins, fs, nMels, 0, effectiveMaxFreq);

      // Calculate expected hop size for the model (HiFi-GAN typically uses hop=256)
      const modelHop = 256;
      const inputFrameRate = fs / hop;
      const modelFrameRate = modelSampleRate / modelHop;

      // Resample mel-spectrogram temporally to match model's expected frame rate
      let finalFrames = frames;
      if (Math.abs(inputFrameRate - modelFrameRate) > 1.0) {
        const frameRatio = modelFrameRate / inputFrameRate;
        finalFrames = Math.max(1, Math.round(frames * frameRatio));
        logFn && logFn(`Resampling mel frames: ${frames} ‚Üí ${finalFrames} (${inputFrameRate.toFixed(1)}‚Üí${modelFrameRate.toFixed(1)} fps)`);

        const resampledMel = new Float32Array(finalFrames * nMels);
        for (let t = 0; t < finalFrames; t++) {
          const srcT = (t / finalFrames) * frames;
          const t0 = Math.floor(srcT);
          const t1 = Math.min(t0 + 1, frames - 1);
          const frac = srcT - t0;

          for (let m = 0; m < nMels; m++) {
            const v0 = melSpec[t0 * nMels + m];
            const v1 = melSpec[t1 * nMels + m];
            resampledMel[t * nMels + m] = v0 * (1 - frac) + v1 * frac;
          }
        }
        melSpec = resampledMel;
      }

      // Convert to log scale and clip (simpler, more robust preprocessing)
      // Most HiFi-GAN models work well with log-mel clipped to [-12, 4]
      let minVal = Infinity, maxVal = -Infinity;
      for (let i = 0; i < melSpec.length; i++) {
        melSpec[i] = Math.log(Math.max(1e-10, melSpec[i]));
        if (melSpec[i] < minVal) minVal = melSpec[i];
        if (melSpec[i] > maxVal) maxVal = melSpec[i];
      }

      logFn && logFn(`Mel range before norm: [${minVal.toFixed(2)}, ${maxVal.toFixed(2)}]`);

      // Simple dynamic range scaling: map [minVal, maxVal] to roughly [-8, 2]
      // This is more robust than mean/std when you have lots of silence
      const targetMin = -8.0;
      const targetMax = 2.0;
      const scale = (targetMax - targetMin) / Math.max(0.1, maxVal - minVal);

      for (let i = 0; i < melSpec.length; i++) {
        melSpec[i] = targetMin + (melSpec[i] - minVal) * scale;
        // Additional clipping for safety
        melSpec[i] = Math.max(-12, Math.min(4, melSpec[i]));
      }

      // Try to infer correct tensor shape from model inputs
      logFn && logFn('Preparing input tensor...');
      const inputName = __vocoderSession.inputNames[0];

      // Prepare input tensor - try [1, nMels, finalFrames] first (HiFi-GAN format)
      const inputTensor = new Float32Array(1 * nMels * finalFrames);
      for (let t = 0; t < finalFrames; t++) {
        for (let m = 0; m < nMels; m++) {
          inputTensor[m * finalFrames + t] = melSpec[t * nMels + m];
        }
      }

      // Run inference
      const inputNames = __vocoderSession.inputNames;
      logFn && logFn(`Running neural vocoder inference (inputs: ${inputNames.join(', ')})...`);
      const feeds = {};
      feeds[inputName] = new ort.Tensor('float32', inputTensor, [1, nMels, finalFrames]);

      // Handle models with additional inputs (some vocoders need length/noise tensors)
      if (inputNames.length > 1) {
        logFn && logFn(`Model requires ${inputNames.length} inputs, adding defaults...`);
        for (let i = 1; i < inputNames.length; i++) {
          const extraName = inputNames[i];
          try {
            if (extraName.toLowerCase().includes('len') || extraName === 'lengths') {
              feeds[extraName] = new ort.Tensor('int64', new BigInt64Array([BigInt(finalFrames)]), [1]);
              logFn && logFn(`  Added '${extraName}': [${finalFrames}]`);
            } else if (extraName.toLowerCase().includes('noise') || extraName === 'z') {
              const noiseLen = finalFrames * 8;
              const noise = new Float32Array(noiseLen).map(() => Math.random() * 2 - 1);
              feeds[extraName] = new ort.Tensor('float32', noise, [1, 1, noiseLen]);
              logFn && logFn(`  Added '${extraName}': noise`);
            }
          } catch (e) {
            logFn && logFn(`  Warning: couldn't add '${extraName}': ${e.message}`);
          }
        }
      }

      let results;
      try {
        results = await __vocoderSession.run(feeds);
      } catch (err) {
        // If that failed, try alternate shape [1, finalFrames, nMels]
        logFn && logFn(`First shape failed, trying alternate: ${err.message}`);
        const altTensor = new Float32Array(1 * finalFrames * nMels);
        for (let t = 0; t < finalFrames; t++) {
          for (let m = 0; m < nMels; m++) {
            altTensor[t * nMels + m] = melSpec[t * nMels + m];
          }
        }
        feeds[inputName] = new ort.Tensor('float32', altTensor, [1, finalFrames, nMels]);

        try {
          results = await __vocoderSession.run(feeds);
        } catch (err2) {
          logFn && logFn(`ERROR: Model not compatible. Required inputs: ${inputNames.join(', ')}`);
          throw err2;
        }
      }

      const outputName = __vocoderSession.outputNames[0];
      const output = results[outputName];

      logFn && logFn(`Vocoder output shape: ${output.dims.join('x')}`);

      // Extract audio samples
      const audioData = output.data;
      let signal = new Float32Array(audioData.length);
      for (let i = 0; i < audioData.length; i++) {
        signal[i] = audioData[i];
      }

      // Resample if needed
      if (modelSampleRate !== fs) {
        logFn && logFn(`Resampling from ${modelSampleRate}Hz to ${fs}Hz...`);
        signal = resampleAudio(signal, modelSampleRate, fs);
      }

      logFn && logFn(`Generated ${signal.length} samples (${(signal.length / fs).toFixed(2)}s)`);
      return signal;
    }

    /**
     * Simple iSTFT reconstruction with coherent phase (no iterations)
     * Fast single-pass synthesis using expected sinusoidal phase progression
     */
    async function istftReconstruct(magRowsCols, rows, cols, fs, N, hop, kMin, kMax, rowToBin, logFn){
      const preGain = __getPreGain();
      const posBins = Math.floor(N/2);
      const frames = cols;

      logFn && logFn(`iSTFT: frames ${frames}, posBins ${posBins}, k ${kMin}..${kMax}`);

      // Build target magnitude array
      const target = new Array(frames);
      for(let c=0;c<frames;c++){
        let maxA = 0;
        const mag = new Float32Array(posBins);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k>=0 && k<posBins){
            const a = magRowsCols[y*cols + c];
            if(a>mag[k]) mag[k]=a;
            if(a>maxA) maxA=a;
          }
        }
        // Apply noise floor (matching Griffin-Lim)
        const floorA = maxA * 1e-4;
        for(let k=0;k<posBins;k++){ if(mag[k] < floorA) mag[k] = 0; }
        const specScale = N / 2;
        for(let k=0;k<posBins;k++){ mag[k] *= specScale * preGain; }
        target[c]=mag;
      }

      // Build spectrum with coherent phase
      const spec = new Array(frames);
      for(let c=0;c<frames;c++){
        const re=new Float32Array(N), im=new Float32Array(N);
        for(let k=0;k<posBins;k++){
          const a = target[c][k];
          // Coherent phase: bin k advances by 2œÄk per frame (hop samples)
          const ph = 2 * Math.PI * k * c * hop / N;
          re[k]=a*Math.cos(ph); im[k]=a*Math.sin(ph);
        }
        im[0]=0; const ny=posBins; re[ny]=0; im[ny]=0;
        for(let k=1;k<posBins;k++){ re[N-k]=re[k]; im[N-k]=-im[k]; }
        spec[c]={re, im};
      }

      // Single iSTFT pass
      const outLen = hop*(frames - 1) + N;
      const signal = istft({spec, fftSize: N}, hop, outLen);

      logFn && logFn(`Zero Phase complete: ${signal.length} samples (${(signal.length / fs).toFixed(2)}s)`);
      return signal;
    }

    async function griffinLimReconstruct(magRowsCols, rows, cols, fs, N, hop, kMin, kMax, rowToBin, iters, logFn){
      const preGain = __getPreGain();
      const posBins = Math.floor(N/2);
      const frames = cols;
      const target = new Array(frames);
      logFn && logFn(`GL target: frames ${frames}, posBins ${posBins}, k ${kMin}..${kMax}`);
      for(let c=0;c<frames;c++){
        let maxA = 0;
        const mag = new Float32Array(posBins);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k>=0 && k<posBins){
            const a = magRowsCols[y*cols + c];
            if(a>mag[k]) mag[k]=a;
            if(a>maxA) maxA=a;
          }
        }
        const floorA = maxA * 1e-4;
        for(let k=0;k<posBins;k++){ if(mag[k] < floorA) mag[k] = 0; }
        const specScale = N / 2;
        for(let k=0;k<posBins;k++){ mag[k] *= specScale; mag[k] *= preGain; }
        target[c]=mag;
      }

      const spec = new Array(frames);
      // Use coherent initial phase instead of random for better convergence
      // Phase at bin k, frame c: expected phase if signal is continuous sinusoid
      for(let c=0;c<frames;c++){
        const re=new Float32Array(N), im=new Float32Array(N);
        for(let k=0;k<posBins;k++){
          const a = target[c][k];
          // Coherent phase: bin k advances by 2œÄk per frame (hop samples)
          const ph = 2 * Math.PI * k * c * hop / N;
          re[k]=a*Math.cos(ph); im[k]=a*Math.sin(ph);
        }
        im[0]=0; const ny=posBins; re[ny]=0; im[ny]=0;
        for(let k=1;k<posBins;k++){ re[N-k]=re[k]; im[N-k]=-im[k]; }
        spec[c]={re, im};
      }

      const outLen = hop*(frames - 1) + N;
      let signal = istft({spec, fftSize: N}, hop, outLen);

      // Fast Griffin-Lim Algorithm (FGLA) with momentum for faster convergence and less wobble
      // Reference: Perraudin et al., "A fast Griffin-Lim algorithm" (2013)
      const momentum = 0.99; // Set to 0 to disable FGLA momentum
      let prevSignal = null;
      let prevRms = Infinity;
      const earlyStopThreshold = 0.001; // Stop when RMS change < 0.1%
      logFn && logFn('Starting Fast Griffin-Lim (FGLA) with momentum');

      for(let it=0; it<iters; it++){
        if(anyBad(signal)) warnNaNs('Griffin-Lim iteration '+(it+1), 'Signal contains invalid numbers');

        // Apply momentum: accelerate in the direction of change
        let workSignal = signal;
        if(prevSignal && momentum > 0){
          workSignal = new Float32Array(signal.length);
          for(let i=0; i<signal.length; i++){
            workSignal[i] = signal[i] + momentum * (signal[i] - prevSignal[i]);
          }
        }

        const ana = stft(workSignal, N, hop);

        // Standard Griffin-Lim projection: extract phase, apply target magnitude
        for(let c=0;c<frames;c++){
          const re=ana.spec[c].re, im=ana.spec[c].im;
          for(let k=0;k<posBins;k++){
            const ph = Math.atan2(im[k], re[k]);
            re[k]=target[c][k]*Math.cos(ph);
            im[k]=target[c][k]*Math.sin(ph);
          }
          // Apply conjugate symmetry for real signal
          for(let k=1;k<posBins;k++){
            ana.spec[c].re[N-k]=ana.spec[c].re[k];
            ana.spec[c].im[N-k]=-ana.spec[c].im[k];
          }
          ana.spec[c].im[0]=0;
          ana.spec[c].re[posBins]=0;
          ana.spec[c].im[posBins]=0;
        }

        prevSignal = signal;
        signal = istft({spec: ana.spec, fftSize: N}, hop, outLen);
        let rms=0;
        for(let i=0;i<signal.length;i++){ const s=signal[i]; rms+=s*s; }
        rms=Math.sqrt(rms/Math.max(1,signal.length));

        // Early stopping: check if RMS change is below threshold
        const rmsChange = Math.abs(rms - prevRms) / Math.max(prevRms, 1e-10);
        if(it%2===0){ logFn && logFn(`Griffin-Lim iter ${it+1}/${iters} (RMS: ${rms.toFixed(4)}, Œî: ${(rmsChange*100).toFixed(2)}%)`); await yieldUI(); }

        if(it >= 3 && rmsChange < earlyStopThreshold){
          logFn && logFn(`Early stop at iter ${it+1}: converged (Œî ${(rmsChange*100).toFixed(3)}% < ${earlyStopThreshold*100}%)`);
          break;
        }
        prevRms = rms;
      }
      return signal;
    }

    /**
     * Hybrid PGHI + Griffin-Lim reconstruction
     * Uses PGHI for initial phase estimation, then refines with GL iterations
     */
    async function pghiGLHybridReconstruct(magRowsCols, rows, cols, fs, N, hop, kMin, kMax, rowToBin, iters, logFn){
      const preGain = __getPreGain();
      const posBins = Math.floor(N/2);
      const frames = cols;

      // Build target magnitude array (same as GL)
      const target = new Array(frames);
      logFn && logFn(`Hybrid: building target magnitudes...`);
      for(let c=0;c<frames;c++){
        let maxA = 0;
        const mag = new Float32Array(posBins);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k>=0 && k<posBins){
            const a = magRowsCols[y*cols + c];
            if(a>mag[k]) mag[k]=a;
            if(a>maxA) maxA=a;
          }
        }
        // Apply noise floor (matching Griffin-Lim)
        const floorA = maxA * 1e-4;
        for(let k=0;k<posBins;k++){ if(mag[k] < floorA) mag[k] = 0; }
        const specScale = N / 2;
        for(let k=0;k<posBins;k++){ mag[k] *= specScale; mag[k] *= preGain; }
        target[c]=mag;
      }

      // === PGHI Phase Estimation ===
      logFn && logFn(`Hybrid: PGHI phase estimation...`);
      await new Promise(r=>requestAnimationFrame(r));

      const logMag = new Float32Array(rows*cols);
      for(let i=0;i<magRowsCols.length;i++) logMag[i] = Math.log(magRowsCols[i] + 1e-9);

      const dT = new Float32Array(rows*cols);
      const dF = new Float32Array(rows*cols);
      for(let y=0;y<rows;y++){
        for(let x=1;x<cols-1;x++){
          const idx = y*cols + x;
          dT[idx] = (logMag[y*cols + x+1] - logMag[y*cols + x-1]) * 0.5;
        }
      }
      for(let x=0;x<cols;x++){
        for(let y=1;y<rows-1;y++){
          const idx = y*cols + x;
          dF[idx] = (logMag[(y+1)*cols + x] - logMag[(y-1)*cols + x]) * 0.5;
        }
      }

      const dPhiT = new Float32Array(rows*cols);
      const dPhiF = new Float32Array(rows*cols);
      const twoPi = 2 * Math.PI;
      const gamma = (N * hop) / (8 * Math.log(2));
      const scaleT = gamma / (N * N);
      const scaleF = 1 / gamma;
      for(let y = 0; y < rows; y++){
        for(let x = 0; x < cols; x++){
          const idx = y * cols + x;
          dPhiT[idx] = scaleT * dF[idx];
          dPhiF[idx] = scaleF * dT[idx];
        }
      }

      // Heap-based phase propagation
      const phase = new Float32Array(rows*cols).fill(NaN);
      const visited = new Uint8Array(rows*cols);
      const heap = new MaxHeap();

      let seedIdx = 0, maxMag = 0;
      for(let i=0; i<magRowsCols.length; i++){
        if(magRowsCols[i] > maxMag){ maxMag = magRowsCols[i]; seedIdx = i; }
      }

      phase[seedIdx] = 0;
      visited[seedIdx] = 1;
      heap.push(magRowsCols[seedIdx], seedIdx);

      while(heap.length > 0){
        const entry = heap.pop();
        if(!entry) break;
        const [magVal, idx] = entry;
        const y = Math.floor(idx / cols);
        const x = idx - y * cols;
        const k = rowToBin[y];
        const carrier = twoPi * k * hop / N;

        if(x + 1 < cols && !visited[idx + 1]){
          phase[idx + 1] = phase[idx] + carrier + dPhiT[idx];
          visited[idx + 1] = 1;
          heap.push(magRowsCols[idx + 1], idx + 1);
        }
        if(x > 0 && !visited[idx - 1]){
          phase[idx - 1] = phase[idx] - carrier - dPhiT[idx];
          visited[idx - 1] = 1;
          heap.push(magRowsCols[idx - 1], idx - 1);
        }
        if(y + 1 < rows && !visited[idx + cols]){
          phase[idx + cols] = phase[idx] + dPhiF[idx];
          visited[idx + cols] = 1;
          heap.push(magRowsCols[idx + cols], idx + cols);
        }
        if(y > 0 && !visited[idx - cols]){
          phase[idx - cols] = phase[idx] - dPhiF[idx];
          visited[idx - cols] = 1;
          heap.push(magRowsCols[idx - cols], idx - cols);
        }
      }

      // Build initial spectrum using PGHI phase
      logFn && logFn(`Hybrid: building initial spectrum from PGHI phase...`);
      const spec = new Array(frames);
      for(let c=0;c<frames;c++){
        const re = new Float32Array(N);
        const im = new Float32Array(N);
        for(let y=0;y<rows;y++){
          const k = rowToBin[y];
          if(k<=0 || k>=posBins) continue;
          const idx = y*cols + c;
          const a = target[c][k];
          const ph = isNaN(phase[idx]) ? 0 : phase[idx];
          if(a > 0){
            re[k] = a*Math.cos(ph);
            im[k] = a*Math.sin(ph);
          }
        }
        im[0]=0; re[posBins]=0; im[posBins]=0;
        for(let k=1;k<posBins;k++){ re[N-k]=re[k]; im[N-k]=-im[k]; }
        spec[c] = {re, im};
      }

      const outLen = hop*(frames - 1) + N;
      let signal = istft({spec, fftSize: N}, hop, outLen);

      // === Griffin-Lim Refinement ===
      logFn && logFn(`Hybrid: starting GL refinement (${iters} iterations max)...`);
      const momentum = 0.99; // Set to 0 to disable FGLA momentum
      let prevSignal = null;
      let prevRms = Infinity;
      const earlyStopThreshold = 0.001;

      for(let it=0; it<iters; it++){
        let workSignal = signal;
        if(prevSignal && momentum > 0){
          workSignal = new Float32Array(signal.length);
          for(let i=0; i<signal.length; i++){
            workSignal[i] = signal[i] + momentum * (signal[i] - prevSignal[i]);
          }
        }

        const ana = stft(workSignal, N, hop);

        for(let c=0;c<frames;c++){
          const re=ana.spec[c].re, im=ana.spec[c].im;
          for(let k=0;k<posBins;k++){
            const ph = Math.atan2(im[k], re[k]);
            re[k]=target[c][k]*Math.cos(ph);
            im[k]=target[c][k]*Math.sin(ph);
          }
          for(let k=1;k<posBins;k++){
            ana.spec[c].re[N-k]=ana.spec[c].re[k];
            ana.spec[c].im[N-k]=-ana.spec[c].im[k];
          }
          ana.spec[c].im[0]=0;
          ana.spec[c].re[posBins]=0;
          ana.spec[c].im[posBins]=0;
        }

        prevSignal = signal;
        signal = istft({spec: ana.spec, fftSize: N}, hop, outLen);

        let rms=0;
        for(let i=0;i<signal.length;i++){ const s=signal[i]; rms+=s*s; }
        rms=Math.sqrt(rms/Math.max(1,signal.length));

        const rmsChange = Math.abs(rms - prevRms) / Math.max(prevRms, 1e-10);
        if(it%2===0){ logFn && logFn(`Hybrid GL iter ${it+1}/${iters} (RMS: ${rms.toFixed(4)}, Œî: ${(rmsChange*100).toFixed(2)}%)`); await yieldUI(); }

        if(it >= 3 && rmsChange < earlyStopThreshold){
          logFn && logFn(`Hybrid early stop at iter ${it+1}: converged`);
          break;
        }
        prevRms = rms;
      }

      logFn && logFn(`Hybrid reconstruction complete`);
      return signal;
    }

    function readU32BE(u8, off){
      return (u8[off]<<24) | (u8[off+1]<<16) | (u8[off+2]<<8) | (u8[off+3]);
    }
    
    function parsePngText(u8){
      const out = {};
      const sig = [137,80,78,71,13,10,26,10];
      for(let i=0;i<8;i++){ if(u8[i]!==sig[i]) return out; }
      let p = 8;
      if(p+8 <= u8.length){
        const lenIHDR = (u8[p]<<24)|(u8[p+1]<<16)|(u8[p+2]<<8)|u8[p+3]; p+=4;
        const typeIHDR = String.fromCharCode(u8[p],u8[p+1],u8[p+2],u8[p+3]); p+=4;
        if(typeIHDR==='IHDR' && p+lenIHDR <= u8.length){
          const w = (u8[p]<<24)|(u8[p+1]<<16)|(u8[p+2]<<8)|u8[p+3];
          const h = (u8[p+4]<<24)|(u8[p+5]<<16)|(u8[p+6]<<8)|u8[p+7];
          out.__width = (w>>>0);
          out.__height = (h>>>0);
        }
        p += lenIHDR + 4;
      }
      while(p+8 <= u8.length){
        const len = (u8[p]<<24)|(u8[p+1]<<16)|(u8[p+2]<<8)|u8[p+3]; p+=4;
        const type = String.fromCharCode(u8[p],u8[p+1],u8[p+2],u8[p+3]); p+=4;
        if(type === 'tEXt' && p+len <= u8.length){
          const data = u8.subarray(p, p+len);
          const nul = data.indexOf(0);
          if(nul>0){
            const k = new TextDecoder('ascii').decode(data.subarray(0,nul));
            const v = new TextDecoder('utf-8').decode(data.subarray(nul+1));
            out[k] = v;
          }
        }
        p += len + 4;
        if(type === 'IEND') break;
      }
      return out;
    }
    
    function applySpectroMeta(metaMap){
      try{ window.__lastMeta = Object.assign({}, metaMap); }catch(_e){}
      
      // Only apply metadata once - don't override user changes
      if(window.__metadataAlreadyApplied) return;
      window.__metadataAlreadyApplied = true;
      
      // Apply colormap from metadata if present
      if(metaMap.colormap){
        const cmap = metaMap.colormap.toLowerCase();
        const radios = document.querySelectorAll('input[name="colormap"]');
        radios.forEach(r=>{
          if(r.value.toLowerCase() === cmap){
            r.checked = true;
          }
        });
      
        // Update the hidden select mirror if used
        const sel = document.getElementById('colormapSelect');
        if(sel){
          for(const opt of sel.options){
            if(opt.value.toLowerCase() === cmap){
              sel.value = opt.value;
              break;
            }
          }
        }
      }

      if(metaMap.invertColors !== undefined){
        const inv = metaMap.invertColors.toLowerCase() === 'true';
        const invChk = document.getElementById('invertColorsIn');
        if(invChk){
          invChk.checked = inv;
        }
      }

      const byId = (id)=>document.getElementById(id);
      const setVal = (id, v)=>{ const el=byId(id); if(el){ el.value = String(v); } };
      const setCheck = (id, on)=>{ const el=byId(id); if(el){ el.checked = !!on; } };

      if(metaMap.fftSize) setVal('fftSize', metaMap.fftSize);
      if(metaMap.freqScale){ if(byId('freqScale')) setVal('freqScale', String(metaMap.freqScale)); }
      else if(metaMap.scale){ if(byId('freqScale')) setVal('freqScale', String(metaMap.scale)); }
      // Set Mel Type from metadata (SpectroGhost uses 'htk', librosa/NVIDIA use 'slaney')
      if(metaMap.melType){ setVal('melType', String(metaMap.melType)); }
      if(metaMap.minHz) setVal('minFreq', metaMap.minHz);
      if(metaMap.maxHz) setVal('maxFreq', metaMap.maxHz);
      if(metaMap.__height) setVal('cropHeight', metaMap.__height);
      if(metaMap.invertColors!=null){ const v = String(metaMap.invertColors).toLowerCase(); const on = (v==='1'||v==='true'); const el=document.getElementById('invertColorsIn'); if(el) el.checked=on; }
      // Auto-set sRGB gamma checkbox from metadata (only at load time, not re-render)
      { const srgbEl = document.getElementById('srgbGamma'); if(srgbEl){ srgbEl.checked = (String(metaMap.srgbGamma).toLowerCase() === 'true'); } }
      if(metaMap.dynRange) {
        setVal('dynRange', metaMap.dynRange);
        // For SpectroGhost files, set Noise Floor to match Dynamic Range
        // SpectroGhost files have fftSize and hop in metadata
        if(metaMap.fftSize && metaMap.hop) {
          setVal('lowFloorDb', metaMap.dynRange);
        }
      }
      if(metaMap.duration_sec || metaMap.durationSec || metaMap.duration) {
        const dur = metaMap.duration_sec || metaMap.durationSec || metaMap.duration;
        setVal('assumedDurationSec', dur);
      }
      if(metaMap.sampleRate && byId('sampleRate')) setVal('sampleRate', metaMap.sampleRate);

      // Update Mel Type dropdown visibility based on loaded scale
      if(window.updateMelTypeVisibility) window.updateMelTypeVisibility();
    }

    (function(){
      const ip = document.getElementById('imageInput');
      if(!ip) return;
      ip.addEventListener('change', async (ev)=>{
        // Reset metadata state when a new image is loaded
        window.__metadataAlreadyApplied = false;
        window.__lastMeta = null;  // Clear previous metadata to prevent stale data

        try{
          const f = ev.target.files && ev.target.files[0];
          if(!f) return;
          const u8 = new Uint8Array(await f.arrayBuffer());
          const meta = parsePngText(u8);
          if(meta && Object.keys(meta).length){
            console.log('[meta] PNG tEXt found', meta);
            applySpectroMeta(meta);
          } else {
            console.log('[meta] no PNG tEXt found, metadata cleared');
          }
        }catch(e){ console.warn('[meta] read failed', e); }
      });
    })();

    (function(){
      const ip = document.getElementById('imageInput');
      if(!ip) return;
      ip.addEventListener('change', async (ev)=>{
        const file = ev.target.files && ev.target.files[0];
        if(!file) return;

        const url = URL.createObjectURL(file);
        const img = new Image();
        img.src = url;

        try {
          // Wait for image to be fully decoded before drawing (critical for JPEG reliability)
          await img.decode();
          // Use naturalWidth/naturalHeight to get actual pixel dimensions (ignores device pixel ratio)
          canvas.width = img.naturalWidth;
          canvas.height = img.naturalHeight;
          ctx.imageSmoothingEnabled = false;
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          ctx.drawImage(img, 0, 0);

          // Wait for canvas to commit pixels (critical for JPEG reliability)
          await new Promise(resolve => requestAnimationFrame(() => requestAnimationFrame(resolve)));

          // Update thumbnail and scale canvas display
          updateThumbnail();
          scaleCanvasDisplay();

          // Store original for adjustments
          if(window.storeOriginalImage) window.storeOriginalImage();
        } finally {
          URL.revokeObjectURL(url);
        }
      });
    })();

    (function(){
      const el = document.getElementById('fftSize');
      if(el){
        el.addEventListener('change', enforceFFTInput);
        el.addEventListener('blur', enforceFFTInput);
      }
    })();

    (function(){
      const __dlBtn = document.getElementById('downloadBtn');
      if(__dlBtn && !__dlBtn.__bound){
        __dlBtn.addEventListener('click', ()=>{
          const url = __dlBtn.dataset && __dlBtn.dataset.url;
          if(!url){ log('No audio available to download yet.'); return; }
          const a = document.createElement('a');
          a.href = url;
          a.download = 'resounder_inverted.wav';
          document.body.appendChild(a);
          a.click();
          a.remove();
        });
        __dlBtn.__bound = true;
      }
    })();

    // Clipboard paste handler for images
    (function(){
      async function loadImageFromBlob(blob) {
        // Reset metadata flag when new image is pasted
        window.__metadataAlreadyApplied = false;
        window.__lastMeta = null;

        // Clear the file input so it doesn't override the pasted image
        const fileInput = document.getElementById('imageInput');
        if(fileInput) fileInput.value = '';

        const url = URL.createObjectURL(blob);
        const img = new Image();
        img.src = url;

        try {
          // Wait for image to be fully decoded before drawing (critical for JPEG reliability)
          await img.decode();
          // Use naturalWidth/naturalHeight to get actual pixel dimensions (ignores device pixel ratio)
          canvas.width = img.naturalWidth;
          canvas.height = img.naturalHeight;
          ctx.imageSmoothingEnabled = false;
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          ctx.drawImage(img, 0, 0);

          // Wait for canvas to commit pixels (critical for JPEG reliability)
          await new Promise(resolve => requestAnimationFrame(() => requestAnimationFrame(resolve)));

          // Update thumbnail and scale canvas display
          updateThumbnail();
          scaleCanvasDisplay();

          // Store original for adjustments
          if(window.storeOriginalImage) window.storeOriginalImage();

          log('Image pasted from clipboard');

          // Try to read metadata from pasted PNG
          try {
            const ab = await blob.arrayBuffer();
            const u8 = new Uint8Array(ab);
            const meta = parsePngText(u8);
            if(meta && Object.keys(meta).length){
              console.log('[meta] PNG tEXt found in pasted image', meta);
              applySpectroMeta(meta);
            }
          } catch(e) {
            console.warn('[meta] read failed', e);
          }
        } catch(err) {
          log('Failed to load pasted image');
          console.error('Image decode error:', err);
        } finally {
          URL.revokeObjectURL(url);
        }
      }

      // Handle paste event
      document.addEventListener('paste', (ev)=>{
        const items = ev.clipboardData?.items;
        if(!items) return;
        
        for(let i=0; i<items.length; i++){
          const item = items[i];
          if(item.type.indexOf('image') !== -1){
            ev.preventDefault();
            const blob = item.getAsFile();
            if(blob){
              loadImageFromBlob(blob);
            }
            break;
          }
        }
      });
      
      log('Paste functionality enabled - press Ctrl+V (or Cmd+V) to paste images');
    })();

    // Camera capture functionality
    (function(){
      const cameraBtn = document.getElementById('cameraBtn');
      const cameraOverlay = document.getElementById('cameraOverlay');
      const cameraClose = document.getElementById('cameraClose');
      const cameraVideo = document.getElementById('cameraVideo');
      const captureBtn = document.getElementById('captureBtn');
      const switchCameraBtn = document.getElementById('switchCameraBtn');
      const flashBtn = document.getElementById('flashBtn');
      const cameraStatus = document.getElementById('cameraStatus');

      if(!cameraBtn || !cameraOverlay || !cameraVideo) return;

      let currentStream = null;
      let facingMode = 'environment'; // Start with back camera
      let torchOn = false;

      // Check if camera is available
      const hasCamera = navigator.mediaDevices && navigator.mediaDevices.getUserMedia;

      if(!hasCamera){
        cameraBtn.style.display = 'none';
        console.log('[camera] MediaDevices API not available');
        return;
      }

      // Start camera
      async function startCamera(){
        try {
          // Stop existing stream if any
          if(currentStream){
            currentStream.getTracks().forEach(track => track.stop());
          }

          cameraStatus.textContent = 'Accessing camera...';
          cameraStatus.classList.remove('error');

          const constraints = {
            video: {
              facingMode: facingMode,
              width: { ideal: 1920 },
              height: { ideal: 1080 }
            }
          };

          currentStream = await navigator.mediaDevices.getUserMedia(constraints);
          cameraVideo.srcObject = currentStream;

          // Wait for video to be ready
          await new Promise((resolve, reject) => {
            cameraVideo.onloadedmetadata = resolve;
            cameraVideo.onerror = reject;
            setTimeout(() => reject(new Error('Video timeout')), 5000);
          });

          await cameraVideo.play();
          cameraStatus.textContent = 'Point camera at spectrogram, then tap capture';

          // Check if torch is supported (with slight delay for capability detection)
          const track = currentStream.getVideoTracks()[0];
          if(track){
            // Some devices need a moment before capabilities are fully available
            setTimeout(() => {
              if(typeof track.getCapabilities !== 'function'){
                console.log('[camera] getCapabilities not supported');
                flashBtn.style.display = 'none';
                return;
              }
              const capabilities = track.getCapabilities();
              console.log('[camera] Track capabilities:', capabilities);

              // Check if torch is a supported capability
              const hasTorch = 'torch' in capabilities && capabilities.torch === true;
              console.log('[camera] Torch supported:', hasTorch);

              if(hasTorch){
                flashBtn.style.display = 'inline-flex';
                // Reset torch state when starting camera
                torchOn = false;
                flashBtn.textContent = 'üî¶';
                flashBtn.classList.remove('active');
                console.log('[camera] Flash button enabled');
              } else {
                flashBtn.style.display = 'none';
                console.log('[camera] Flash button hidden - torch not available');
              }
            }, 500);
          }

        } catch(err){
          console.error('[camera] Error:', err);
          cameraStatus.textContent = 'Camera access denied or unavailable';
          cameraStatus.classList.add('error');

          // Provide more specific error messages
          if(err.name === 'NotAllowedError'){
            cameraStatus.textContent = 'Camera permission denied. Please allow camera access.';
          } else if(err.name === 'NotFoundError'){
            cameraStatus.textContent = 'No camera found on this device.';
          } else if(err.name === 'NotReadableError'){
            cameraStatus.textContent = 'Camera is in use by another application.';
          }
        }
      }

      // Stop camera
      function stopCamera(){
        if(currentStream){
          currentStream.getTracks().forEach(track => track.stop());
          currentStream = null;
        }
        cameraVideo.srcObject = null;
        cameraOverlay.classList.remove('active');
        // Reset flash button
        flashBtn.style.display = 'none';
        torchOn = false;
        flashBtn.textContent = 'üî¶';
        flashBtn.classList.remove('active');
      }

      // Capture frame from video
      function captureFrame(){
        if(!cameraVideo.videoWidth || !cameraVideo.videoHeight){
          cameraStatus.textContent = 'Camera not ready yet...';
          return;
        }

        // Reset metadata flag
        window.__metadataAlreadyApplied = false;
        window.__lastMeta = null;

        // Clear file input
        const fileInput = document.getElementById('imageInput');
        if(fileInput) fileInput.value = '';

        // Draw video frame to canvas
        canvas.width = cameraVideo.videoWidth;
        canvas.height = cameraVideo.videoHeight;
        ctx.imageSmoothingEnabled = false;
        ctx.drawImage(cameraVideo, 0, 0);

        // Update thumbnail and scale
        updateThumbnail();
        scaleCanvasDisplay();

        // Store original for adjustments
        if(window.storeOriginalImage) window.storeOriginalImage();

        // Close camera and stop stream
        stopCamera();

        log('Captured frame from camera (' + canvas.width + 'x' + canvas.height + ')');
      }

      // Switch between front and back camera
      async function switchCamera(){
        facingMode = facingMode === 'environment' ? 'user' : 'environment';
        cameraStatus.textContent = 'Switching camera...';
        await startCamera();
      }

      // Toggle flash/torch
      async function toggleFlash(){
        if(!currentStream) return;
        const track = currentStream.getVideoTracks()[0];
        if(!track) return;

        try {
          torchOn = !torchOn;
          await track.applyConstraints({
            advanced: [{ torch: torchOn }]
          });
          flashBtn.textContent = torchOn ? 'üí°' : 'üî¶';
          flashBtn.classList.toggle('active', torchOn);
          cameraStatus.textContent = torchOn ? 'Flash ON' : 'Flash OFF';
          // Reset status message after a moment
          setTimeout(() => {
            if(cameraOverlay.classList.contains('active')){
              cameraStatus.textContent = 'Point camera at spectrogram, then tap capture';
            }
          }, 1500);
        } catch(err){
          console.error('[camera] Torch error:', err);
          cameraStatus.textContent = 'Flash not available';
        }
      }

      // Event listeners
      cameraBtn.addEventListener('click', () => {
        cameraOverlay.classList.add('active');
        startCamera();
      });

      cameraClose.addEventListener('click', stopCamera);
      captureBtn.addEventListener('click', captureFrame);
      switchCameraBtn.addEventListener('click', switchCamera);
      flashBtn.addEventListener('click', toggleFlash);

      // Close on escape key
      document.addEventListener('keydown', (ev) => {
        if(ev.key === 'Escape' && cameraOverlay.classList.contains('active')){
          stopCamera();
        }
      });

      // Close on overlay click (outside video)
      cameraOverlay.addEventListener('click', (ev) => {
        if(ev.target === cameraOverlay){
          stopCamera();
        }
      });

      log('Camera capture enabled');
    })();

    // Image adjustment functionality
    (function(){
      const adjustPanel = document.getElementById('adjustPanel');
      const adjustHeader = document.getElementById('adjustHeader');

      // Color sliders
      const brightnessSlider = document.getElementById('adjustBrightness');
      const contrastSlider = document.getElementById('adjustContrast');
      const temperatureSlider = document.getElementById('adjustTemperature');
      const brightnessVal = document.getElementById('adjustBrightnessVal');
      const contrastVal = document.getElementById('adjustContrastVal');
      const temperatureVal = document.getElementById('adjustTemperatureVal');

      // Lens, rotation, and keystone sliders
      const lensSlider = document.getElementById('adjustLens');
      const lensVal = document.getElementById('adjustLensVal');
      const rotationSlider = document.getElementById('adjustRotation');
      const rotationVal = document.getElementById('adjustRotationVal');
      const rotate0Btn = document.getElementById('rotate0');
      const rotate90Btn = document.getElementById('rotate90');
      const rotate180Btn = document.getElementById('rotate180');
      const rotate270Btn = document.getElementById('rotate270');
      let baseRotation = 0; // 0, 90, 180, or 270 degrees
      const keystoneVSlider = document.getElementById('keystoneV');
      const keystoneHSlider = document.getElementById('keystoneH');
      const keystoneVVal = document.getElementById('keystoneVVal');
      const keystoneHVal = document.getElementById('keystoneHVal');

      // Crop sliders
      const cropLeftSlider = document.getElementById('cropLeft');
      const cropRightSlider = document.getElementById('cropRight');
      const cropTopSlider = document.getElementById('cropTop');
      const cropBottomSlider = document.getElementById('cropBottom');
      const cropLeftVal = document.getElementById('cropLeftVal');
      const cropRightVal = document.getElementById('cropRightVal');
      const cropTopVal = document.getElementById('cropTopVal');
      const cropBottomVal = document.getElementById('cropBottomVal');

      // Buttons
      const autoBtn = document.getElementById('adjustAutoBtn');
      const resetBtn = document.getElementById('adjustResetBtn');
      const grayscaleBtn = document.getElementById('adjustGrayscaleBtn');
      const vistaBtn = document.getElementById('adjustVistaBtn');
      const saveBtn = document.getElementById('adjustSaveBtn');

      if(!adjustPanel || !brightnessSlider) return;

      // Store original image as an Image element for transforms
      let originalImage = null;
      let isGrayscale = false;

      // Start collapsed by default
      adjustPanel.classList.add('collapsed');

      // Toggle panel collapse
      adjustHeader.addEventListener('click', () => {
        adjustPanel.classList.toggle('collapsed');
      });

      // Store original image when canvas is updated
      window.storeOriginalImage = function(){
        if(canvas.width > 0 && canvas.height > 0){
          // Store as image for geometric transforms
          originalImage = new Image();
          originalImage.onload = function(){
            adjustPanel.classList.add('visible');
            resetAdjustments();
          };
          originalImage.src = canvas.toDataURL();
        }
      };

      // Reset all adjustments to defaults
      function resetAdjustments(){
        brightnessSlider.value = 0;
        contrastSlider.value = 0;
        temperatureSlider.value = 0;
        lensSlider.value = 0;
        rotationSlider.value = 0;
        baseRotation = 0;
        [rotate0Btn, rotate90Btn, rotate180Btn, rotate270Btn].forEach(btn => btn.classList.remove('active'));
        rotate0Btn.classList.add('active');
        keystoneVSlider.value = 0;
        keystoneHSlider.value = 0;
        cropLeftSlider.value = 0;
        cropRightSlider.value = 0;
        cropTopSlider.value = 0;
        cropBottomSlider.value = 0;
        isGrayscale = false;
        grayscaleBtn.style.background = '';
        updateValueDisplays();
        if(originalImage && originalImage.complete){
          canvas.width = originalImage.naturalWidth;
          canvas.height = originalImage.naturalHeight;
          ctx.drawImage(originalImage, 0, 0);
          updateThumbnail();
          scaleCanvasDisplay();
        }
      }

      // Update value displays
      function updateValueDisplays(){
        brightnessVal.textContent = brightnessSlider.value;
        contrastVal.textContent = contrastSlider.value;
        temperatureVal.textContent = temperatureSlider.value;
        lensVal.textContent = lensSlider.value;
        rotationVal.textContent = rotationSlider.value + '¬∞';
        keystoneVVal.textContent = keystoneVSlider.value;
        keystoneHVal.textContent = keystoneHSlider.value;
        cropLeftVal.textContent = cropLeftSlider.value + '%';
        cropRightVal.textContent = cropRightSlider.value + '%';
        cropTopVal.textContent = cropTopSlider.value + '%';
        cropBottomVal.textContent = cropBottomSlider.value + '%';
      }

      // Apply all adjustments (lens ‚Üí rotation ‚Üí keystone ‚Üí crop ‚Üí color)
      function applyAdjustments(){
        if(!originalImage || !originalImage.complete) return;

        const brightness = parseInt(brightnessSlider.value);
        const contrast = parseInt(contrastSlider.value);
        const temperature = parseInt(temperatureSlider.value);
        const lens = parseInt(lensSlider.value);
        const rotation = baseRotation + parseFloat(rotationSlider.value);
        const keystoneV = parseInt(keystoneVSlider.value);
        const keystoneH = parseInt(keystoneHSlider.value);
        const cropLeft = parseFloat(cropLeftSlider.value) / 100;
        const cropRight = parseFloat(cropRightSlider.value) / 100;
        const cropTop = parseFloat(cropTopSlider.value) / 100;
        const cropBottom = parseFloat(cropBottomSlider.value) / 100;

        const origW = originalImage.naturalWidth;
        const origH = originalImage.naturalHeight;

        // Step 1: Apply barrel/pincushion lens correction (centered on original image)
        let sourceCanvas;
        if(lens !== 0){
          const lensCanvas = document.createElement('canvas');
          lensCanvas.width = origW;
          lensCanvas.height = origH;
          const lensCtx = lensCanvas.getContext('2d');

          // Draw original to get pixel data
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = origW;
          tempCanvas.height = origH;
          const tempCtx = tempCanvas.getContext('2d');
          tempCtx.drawImage(originalImage, 0, 0);
          const srcData = tempCtx.getImageData(0, 0, origW, origH);
          const dstData = lensCtx.createImageData(origW, origH);

          const centerX = origW / 2;
          const centerY = origH / 2;
          const maxRadius = Math.sqrt(centerX * centerX + centerY * centerY);
          // Strength: negative corrects barrel (fisheye), positive corrects pincushion
          const strength = lens / 100;

          for(let y = 0; y < origH; y++){
            for(let x = 0; x < origW; x++){
              // Distance from center (normalized)
              const dx = (x - centerX) / maxRadius;
              const dy = (y - centerY) / maxRadius;
              const r = Math.sqrt(dx * dx + dy * dy);

              // Apply radial distortion correction
              // r_src = r_dst * (1 + k * r_dst^2)
              const rCorrected = r * (1 + strength * r * r);

              // Map back to source coordinates
              const srcX = centerX + (dx / (r || 1)) * rCorrected * maxRadius;
              const srcY = centerY + (dy / (r || 1)) * rCorrected * maxRadius;

              // Bilinear interpolation
              const x0 = Math.floor(srcX);
              const y0 = Math.floor(srcY);
              const x1 = x0 + 1;
              const y1 = y0 + 1;
              const xFrac = srcX - x0;
              const yFrac = srcY - y0;

              const dstIdx = (y * origW + x) * 4;

              if(x0 >= 0 && x1 < origW && y0 >= 0 && y1 < origH){
                const idx00 = (y0 * origW + x0) * 4;
                const idx10 = (y0 * origW + x1) * 4;
                const idx01 = (y1 * origW + x0) * 4;
                const idx11 = (y1 * origW + x1) * 4;

                for(let c = 0; c < 4; c++){
                  const v00 = srcData.data[idx00 + c];
                  const v10 = srcData.data[idx10 + c];
                  const v01 = srcData.data[idx01 + c];
                  const v11 = srcData.data[idx11 + c];

                  const top = v00 + (v10 - v00) * xFrac;
                  const bottom = v01 + (v11 - v01) * xFrac;
                  dstData.data[dstIdx + c] = top + (bottom - top) * yFrac;
                }
              } else {
                // Outside bounds - transparent
                dstData.data[dstIdx + 3] = 0;
              }
            }
          }

          lensCtx.putImageData(dstData, 0, 0);
          sourceCanvas = lensCanvas;
        } else {
          // No lens correction - use original directly
          sourceCanvas = document.createElement('canvas');
          sourceCanvas.width = origW;
          sourceCanvas.height = origH;
          const sourceCtx = sourceCanvas.getContext('2d');
          sourceCtx.drawImage(originalImage, 0, 0);
        }

        // Step 2: Apply rotation
        const radians = rotation * Math.PI / 180;
        const cos = Math.abs(Math.cos(radians));
        const sin = Math.abs(Math.sin(radians));
        const rotW = Math.ceil(origW * cos + origH * sin);
        const rotH = Math.ceil(origH * cos + origW * sin);

        const rotCanvas = document.createElement('canvas');
        rotCanvas.width = rotW;
        rotCanvas.height = rotH;
        const rotCtx = rotCanvas.getContext('2d');
        rotCtx.imageSmoothingEnabled = true;
        rotCtx.imageSmoothingQuality = 'high';
        rotCtx.save();
        rotCtx.translate(rotW / 2, rotH / 2);
        rotCtx.rotate(radians);
        rotCtx.drawImage(sourceCanvas, -origW / 2, -origH / 2);
        rotCtx.restore();

        // Step 2: Apply keystone (trapezoidal) correction
        // keystoneV: negative = top narrower, positive = top wider
        // keystoneH: negative = left narrower, positive = left wider
        let warpedCanvas = rotCanvas;
        let warpedW = rotW;
        let warpedH = rotH;

        if(keystoneV !== 0 || keystoneH !== 0){
          warpedCanvas = document.createElement('canvas');
          warpedCanvas.width = rotW;
          warpedCanvas.height = rotH;
          const warpCtx = warpedCanvas.getContext('2d');
          warpCtx.imageSmoothingEnabled = true;
          warpCtx.imageSmoothingQuality = 'high';

          // Use strip-based rendering for keystone correction
          // Use fixed number of strips for consistent quality
          const numStrips = 100;

          if(keystoneV !== 0){
            // Vertical keystone: draw horizontal strips with varying width
            const stripH = Math.ceil(rotH / numStrips) + 1; // +1 for overlap
            for(let i = 0; i < numStrips; i++){
              const srcY = (i / numStrips) * rotH;
              const t = i / (numStrips - 1); // 0 at top, 1 at bottom
              const scale = 1 + (keystoneV / 100) * (2 * t - 1);
              const scaledW = rotW * scale;
              const offsetX = (rotW - scaledW) / 2;
              const destY = srcY;
              warpCtx.drawImage(rotCanvas,
                0, srcY, rotW, stripH,
                offsetX, destY, scaledW, stripH);
            }
          } else {
            warpCtx.drawImage(rotCanvas, 0, 0);
          }

          if(keystoneH !== 0){
            // Horizontal keystone: draw vertical strips with varying height
            const tempCanvas2 = document.createElement('canvas');
            tempCanvas2.width = rotW;
            tempCanvas2.height = rotH;
            const tempCtx2 = tempCanvas2.getContext('2d');
            tempCtx2.imageSmoothingEnabled = true;
            tempCtx2.imageSmoothingQuality = 'high';

            const stripW = Math.ceil(rotW / numStrips) + 1; // +1 for overlap
            for(let i = 0; i < numStrips; i++){
              const srcX = (i / numStrips) * rotW;
              const t = i / (numStrips - 1); // 0 at left, 1 at right
              const scale = 1 + (keystoneH / 100) * (2 * t - 1);
              const scaledH = rotH * scale;
              const offsetY = (rotH - scaledH) / 2;
              const destX = srcX;
              tempCtx2.drawImage(warpedCanvas,
                srcX, 0, stripW, rotH,
                destX, offsetY, stripW, scaledH);
            }
            warpCtx.clearRect(0, 0, rotW, rotH);
            warpCtx.drawImage(tempCanvas2, 0, 0);
          }
        }

        // Step 3: Apply crop to the rotated+keystoned result
        const cropX = Math.floor(warpedW * cropLeft);
        const cropY = Math.floor(warpedH * cropTop);
        const cropW = Math.floor(warpedW * (1 - cropLeft - cropRight));
        const cropH = Math.floor(warpedH * (1 - cropTop - cropBottom));

        if(cropW <= 0 || cropH <= 0) return;

        // Set main canvas to cropped size
        canvas.width = cropW;
        canvas.height = cropH;
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = 'high';
        ctx.drawImage(warpedCanvas, cropX, cropY, cropW, cropH, 0, 0, cropW, cropH);

        // Now apply color adjustments if any
        if(brightness !== 0 || contrast !== 0 || temperature !== 0 || isGrayscale){
          const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
          const data = imgData.data;
          const contrastFactor = (contrast + 100) / 100;

          for(let i = 0; i < data.length; i += 4){
            let r = data[i];
            let g = data[i + 1];
            let b = data[i + 2];

            // Apply grayscale first
            if(isGrayscale){
              const gray = 0.299 * r + 0.587 * g + 0.114 * b;
              r = g = b = gray;
            }

            // Apply brightness
            r += brightness * 2.55;
            g += brightness * 2.55;
            b += brightness * 2.55;

            // Apply contrast
            r = (r - 128) * contrastFactor + 128;
            g = (g - 128) * contrastFactor + 128;
            b = (b - 128) * contrastFactor + 128;

            // Apply temperature
            if(temperature !== 0){
              const tempShift = temperature * 0.5;
              r += tempShift;
              b -= tempShift;
              if(temperature > 0) g += tempShift * 0.3;
            }

            // Clamp
            data[i] = Math.max(0, Math.min(255, r));
            data[i + 1] = Math.max(0, Math.min(255, g));
            data[i + 2] = Math.max(0, Math.min(255, b));
          }

          ctx.putImageData(imgData, 0, 0);
        }

        updateThumbnail();
        scaleCanvasDisplay();
      }

      // Grayscale toggle
      function toggleGrayscale(){
        isGrayscale = !isGrayscale;
        grayscaleBtn.style.background = isGrayscale ? 'var(--accent-hover)' : '';
        applyAdjustments();
        log('Grayscale ' + (isGrayscale ? 'enabled' : 'disabled'));
      }

      // Vista filter: preset values for bright, contrasty, warm look
      function applyVista(){
        // Vista-like preset: fixed values (not cumulative)
        brightnessSlider.value = 15;
        contrastSlider.value = 30;
        temperatureSlider.value = 8;
        updateValueDisplays();
        applyAdjustments();
        log('Vista preset applied');
      }

      // Auto-levels: stretch histogram to full range
      function autoLevels(){
        if(!originalImage || !originalImage.complete) return;
        if(canvas.width <= 0 || canvas.height <= 0) return;

        // Reset brightness/contrast to analyze the base transformed image
        const savedBrightness = brightnessSlider.value;
        const savedContrast = contrastSlider.value;
        const savedTemperature = temperatureSlider.value;
        brightnessSlider.value = 0;
        contrastSlider.value = 0;
        temperatureSlider.value = 0;

        // Apply transforms with neutral color settings
        applyAdjustments();

        // Get canvas data (after rotation, keystone, crop, grayscale but before brightness/contrast)
        const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const data = imgData.data;
        let minVal = 255, maxVal = 0;

        // Find min/max luminance (skip transparent and near-black pixels from rotation borders)
        for(let i = 0; i < data.length; i += 4){
          if(data[i + 3] < 200) continue; // Skip transparent/semi-transparent
          const lum = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
          if(lum < minVal) minVal = lum;
          if(lum > maxVal) maxVal = lum;
        }

        const range = maxVal - minVal;
        if(range < 10){
          // Restore saved values
          brightnessSlider.value = savedBrightness;
          contrastSlider.value = savedContrast;
          temperatureSlider.value = savedTemperature;
          applyAdjustments();
          log('Auto levels: image already has good contrast');
          return;
        }

        // Calculate adjustments to stretch histogram
        const midOriginal = (minVal + maxVal) / 2;
        const midTarget = 127.5;
        const brightnessAdj = Math.round((midTarget - midOriginal) / 2.55);
        const contrastAdj = Math.round((255 / range - 1) * 100);

        brightnessSlider.value = Math.max(-100, Math.min(100, brightnessAdj));
        contrastSlider.value = Math.max(-100, Math.min(100, contrastAdj));
        temperatureSlider.value = savedTemperature; // Restore temperature
        updateValueDisplays();
        applyAdjustments();

        log('Auto levels: brightness ' + brightnessSlider.value + ', contrast ' + contrastSlider.value);
      }

      // Event listeners for all sliders
      const allSliders = [brightnessSlider, contrastSlider, temperatureSlider,
                          lensSlider, rotationSlider, keystoneVSlider, keystoneHSlider,
                          cropLeftSlider, cropRightSlider,
                          cropTopSlider, cropBottomSlider];

      allSliders.forEach(slider => {
        slider.addEventListener('input', () => {
          updateValueDisplays();
          applyAdjustments();
        });
      });

      // Rotation button event listeners
      function setBaseRotation(deg){
        baseRotation = deg;
        // Update active state on buttons
        [rotate0Btn, rotate90Btn, rotate180Btn, rotate270Btn].forEach(btn => {
          btn.classList.remove('active');
        });
        if(deg === 0) rotate0Btn.classList.add('active');
        else if(deg === 90) rotate90Btn.classList.add('active');
        else if(deg === 180) rotate180Btn.classList.add('active');
        else if(deg === 270) rotate270Btn.classList.add('active');
        applyAdjustments();
      }

      rotate0Btn.addEventListener('click', () => setBaseRotation(0));
      rotate90Btn.addEventListener('click', () => setBaseRotation(90));
      rotate180Btn.addEventListener('click', () => setBaseRotation(180));
      rotate270Btn.addEventListener('click', () => setBaseRotation(270));

      // Save adjusted image
      function saveAdjustedImage(){
        if(canvas.width <= 0 || canvas.height <= 0){
          log('No image to save');
          return;
        }
        canvas.toBlob(function(blob){
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = 'adjusted-spectrogram.png';
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
          log('Saved adjusted image');
        }, 'image/png');
      }

      // Button handlers
      autoBtn.addEventListener('click', autoLevels);
      resetBtn.addEventListener('click', resetAdjustments);
      grayscaleBtn.addEventListener('click', toggleGrayscale);
      vistaBtn.addEventListener('click', applyVista);
      saveBtn.addEventListener('click', saveAdjustedImage);

      log('Image adjustments enabled');
    })();

  </script>

  <!-- License Footer -->
  <div class="license-footer">
    <a href="https://youtube.com/@CLU-NQR" target="_blank">YouTube</a> &middot;
    <a href="https://discord.gg/HT9YE8rvuN" target="_blank">Discord</a> &middot;
    <a href="https://nqrlabs.com" target="_blank">NQR Labs</a> &middot;
    <a href="https://github.com/NQRLabs" target="_blank">GitHub</a>
    <br>
    &copy; 2025 NQR &middot; <a id="licenseLink">License</a>
  </div>

  <!-- License Modal -->
  <div class="license-overlay" id="licenseOverlay"></div>
  <div class="license-modal" id="licenseModal">
    <span class="license-modal-close" id="licenseClose">&times;</span>
    <h3 style="text-align:center;">ReSounder License</h3>
    <pre>
ReSounder - MIT License

Copyright &copy; 2025 NQR

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</pre>
  </div>

  <!-- License and Tips Modal Handler Script - Must be after the HTML elements -->
  <script>
    (function(){
      const licenseLink = document.getElementById('licenseLink');
      const licenseModal = document.getElementById('licenseModal');
      const licenseOverlay = document.getElementById('licenseOverlay');
      const licenseClose = document.getElementById('licenseClose');

      if(!licenseLink || !licenseModal || !licenseOverlay || !licenseClose) return;

      function showLicense() {
        licenseModal.classList.add('show');
        licenseOverlay.classList.add('show');
      }

      function hideLicense() {
        licenseModal.classList.remove('show');
        licenseOverlay.classList.remove('show');
      }

      licenseLink.addEventListener('click', showLicense);
      licenseClose.addEventListener('click', hideLicense);
      licenseOverlay.addEventListener('click', hideLicense);

      const tipLink = document.getElementById('tipLink');
      const tipModal = document.getElementById('tipModal');
      const tipOverlay = document.getElementById('tipOverlay');
      const tipClose = document.getElementById('tipClose');

      if(!tipLink || !tipModal || !tipOverlay || !tipClose) return;

      function showtip() {
        tipModal.classList.add('show');
        tipOverlay.classList.add('show');
      }

      function hidetip() {
        tipModal.classList.remove('show');
        tipOverlay.classList.remove('show');
      }

      tipLink.addEventListener('click', showtip);
      tipClose.addEventListener('click', hidetip);
      tipOverlay.addEventListener('click', hidetip);
    })();
  </script>
</body>
</html>
